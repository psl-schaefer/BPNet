[
  {
    "objectID": "code/02_prepare_input.html",
    "href": "code/02_prepare_input.html",
    "title": "Prepare Input",
    "section": "",
    "text": "Here we generate the model input based on the raw ChIP-Nexus data."
  },
  {
    "objectID": "code/02_prepare_input.html#data-download",
    "href": "code/02_prepare_input.html#data-download",
    "title": "Prepare Input",
    "section": "3.1 Data Download",
    "text": "3.1 Data Download\n\nThe data can be downloaded from: https://zenodo.org/records/3371216 (~ 30 GBs) as shown in the download.qmd file.\n\n\n\nCode\ndata_dir &lt;- file.path(\"..\", \"data\")"
  },
  {
    "objectID": "code/02_prepare_input.html#output-directory",
    "href": "code/02_prepare_input.html#output-directory",
    "title": "Prepare Input",
    "section": "3.2 Output Directory",
    "text": "3.2 Output Directory\n\n\nCode\noutput_dir &lt;- file.path(\"..\", \"prc\")\nfigure_dir &lt;- file.path(\"..\", \"figures\", \"prepare_input\")\ndir.create(output_dir, recursive=TRUE, showWarnings=FALSE)\ndir.create(figure_dir, recursive=TRUE, showWarnings=FALSE)\n\nTFs &lt;- c(\"Sox2\", \"Oct4\", \"Klf4\", \"Nanog\")\n\npurrr::walk(c(TFs, \"patchcap\"), function(dir_name) {\n  dir.create(file.path(output_dir, dir_name), recursive=TRUE, showWarnings=FALSE)\n})"
  },
  {
    "objectID": "code/02_prepare_input.html#peak-width",
    "href": "code/02_prepare_input.html#peak-width",
    "title": "Prepare Input",
    "section": "3.3 Peak Width",
    "text": "3.3 Peak Width\nAs in the BPNet paper, we are using a peak width of 1000 bp, meaning we consider 500 bp up- and downstream of the ChIP-seq peaks.\n\n\nCode\npeak_width &lt;- 1000"
  },
  {
    "objectID": "code/02_prepare_input.html#chromosome-traintunetest-split",
    "href": "code/02_prepare_input.html#chromosome-traintunetest-split",
    "title": "Prepare Input",
    "section": "3.4 Chromosome Train/Tune/Test split",
    "text": "3.4 Chromosome Train/Tune/Test split\n\n\nCode\nall_chroms &lt;- paste0(\"chr\", c(1:19, \"X\", \"Y\"))\n\n# we use the same train/tune/test split as in the BPnet paper\nchrom_list &lt;- list(\"tune\" = c(\"chr2\", \"chr3\", \"chr4\"), # tune set (hyperparameter tuning): chromosomes 2, 3, 4\n                   \"test\" = c(\"chr1\", \"chr8\", \"chr9\")) # test set (performance evaluation): chromosome 1, 8, 9\nchrom_list$train &lt;- setdiff(all_chroms, c(chrom_list$tune, chrom_list$test)) # train set: all other chromosomes\nchrom_list\n\n\n$tune\n[1] \"chr2\" \"chr3\" \"chr4\"\n\n$test\n[1] \"chr1\" \"chr8\" \"chr9\"\n\n$train\n [1] \"chr5\"  \"chr6\"  \"chr7\"  \"chr10\" \"chr11\" \"chr12\" \"chr13\" \"chr14\" \"chr15\"\n[10] \"chr16\" \"chr17\" \"chr18\" \"chr19\" \"chrX\"  \"chrY\""
  },
  {
    "objectID": "code/02_prepare_input.html#colors",
    "href": "code/02_prepare_input.html#colors",
    "title": "Prepare Input",
    "section": "3.5 Colors",
    "text": "3.5 Colors\n\n\nCode\ncolors = c(\"Klf4\" = \"#92C592\",\n           \"Nanog\" = \"#FFE03F\",\n           \"Oct4\" = \"#CD5C5C\",\n           \"Sox2\" = \"#849EEB\",\n           \"patchcap\" = \"#827F81\")"
  },
  {
    "objectID": "code/02_prepare_input.html#distribution-of-the-macs-scores",
    "href": "code/02_prepare_input.html#distribution-of-the-macs-scores",
    "title": "Prepare Input",
    "section": "6.1 Distribution of the MACS Scores",
    "text": "6.1 Distribution of the MACS Scores\n\nWe see that the distribution of MACS scores (qValues) is quite comparable for the different TFs.\n\n\n\nCode\np &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  ggplot() +\n  geom_density(aes(x=log2(qValue), color=TF), alpha=0.4, fill=NA) +\n  labs(x=\"Log2 qValue\", y=\"Density\", color=\"TF\") +\n  scale_color_manual(values=colors) +\n  theme_bw()\nggsave(filename = file.path(figure_dir, \"macs2_scores_per_tf.pdf\"),\n       plot = p, width = 4, height = 4)\np +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "code/02_prepare_input.html#number-of-peaks-per-tf",
    "href": "code/02_prepare_input.html#number-of-peaks-per-tf",
    "title": "Prepare Input",
    "section": "6.2 Number of Peaks per TF",
    "text": "6.2 Number of Peaks per TF\n\nHowever the number of peaks is quite different. There are many more peaks for Nanog and Klf4.\nWhat does this mean for the training?\n\n\n\nCode\np &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  ggplot() +\n  geom_bar(aes(y=TF, fill=TF), alpha=0.4, width=0.4, color=\"black\") +\n  labs(x=\"Number of Peaks\", y=\"TF\") +\n  theme_bw() +\n  scale_fill_manual(values=colors)\nggsave(filename = file.path(figure_dir, \"n_peaks_per_tf.pdf\"),\n       plot = p, width = 4, height = 4)\np +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "code/02_prepare_input.html#examples-highest-scoring-peaks",
    "href": "code/02_prepare_input.html#examples-highest-scoring-peaks",
    "title": "Prepare Input",
    "section": "8.1 Examples: Highest Scoring Peaks",
    "text": "8.1 Examples: Highest Scoring Peaks\n\n\nClick to expand\n\n\n\nCode\ntest_df &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"train\") %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::group_by(TF) %&gt;%\n  slice_max(order_by=qValue, n=2) %&gt;%\n  select(Region, TF, qValue)\n\npurrr::walk(1:nrow(test_df), function(i) {\n  test_instance &lt;- unlist(test_df[i, ])\n  purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                 minus = -tf_counts[[tf]]$train$neg[match(test_instance[\"Region\"], seq_names$train), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=name)) +\n  facet_wrap(~TF, scales=\"free_y\") +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=paste0(\"Peak \", test_instance[\"Region\"], \" | \", test_instance[\"TF\"], \n                    \" | \", test_instance[\"qValue\"])) -&gt; p\n  print(p)\n})"
  },
  {
    "objectID": "code/02_prepare_input.html#examples-low-scoring-peaks",
    "href": "code/02_prepare_input.html#examples-low-scoring-peaks",
    "title": "Prepare Input",
    "section": "8.2 Examples: Low Scoring Peaks",
    "text": "8.2 Examples: Low Scoring Peaks\n\n\nClick to expand\n\n\n\nCode\nset.seed(42)\ntest_df &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"train\") %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::group_by(TF) %&gt;%\n  slice_min(order_by=qValue, n=2) %&gt;%\n  select(Region, TF, qValue)\n\npurrr::walk(1:nrow(test_df), function(i) {\n  test_instance &lt;- unlist(test_df[i, ])\n  purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                 minus = -tf_counts[[tf]]$train$neg[match(test_instance[\"Region\"], seq_names$train), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=name)) +\n  facet_wrap(~TF, scales=\"free_y\") +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=paste0(\"Peak \", test_instance[\"Region\"], \" | \", test_instance[\"TF\"], \n                    \" | \", test_instance[\"qValue\"])) -&gt; p\n  print(p)\n})"
  },
  {
    "objectID": "code/02_prepare_input.html#examples-highest-scoring-peaks-with-bias",
    "href": "code/02_prepare_input.html#examples-highest-scoring-peaks-with-bias",
    "title": "Prepare Input",
    "section": "9.1 Examples: Highest Scoring Peaks with Bias",
    "text": "9.1 Examples: Highest Scoring Peaks with Bias\n\n\nCode\ntest_instance &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"test\") %&gt;%\n  dplyr::filter(seqnames==\"chr1\", start &gt;= 180924752-1000, end &lt;= 180925152+1000) %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::select(Region, TF, qValue) %&gt;%\n  .[1, ]\nprint(test_instance)\n\n\n                    Region   TF   qValue\n1 chr1:180924435-180925434 Sox2 436.0653\n\n\nCode\np &lt;- purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$test$pos[match(test_instance[\"Region\"], seq_names$test), ],\n                 minus = -tf_counts[[tf]]$test$neg[match(test_instance[\"Region\"], seq_names$test), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  rbind(\n    tibble::tibble(position=-499:500, \n                   plus = ctrl_counts$test$pos[match(test_instance[\"Region\"], seq_names$test), ],\n                   minus = -ctrl_counts$test$neg[match(test_instance[\"Region\"], seq_names$test), ],\n                   TF = \"patchcap\", p_name = test_instance[\"Region\"])\n  ) %&gt;%\n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  dplyr::mutate(TF = factor(TF, levels=names(colors))) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=TF, alpha=name), size=0.2) +\n  facet_wrap(~TF, ncol=1, scales=\"free_y\") +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=test_instance[\"Region\"]) +\n  #scale_color_manual(values=c(\"minus\"=\"darkred\", \"plus\"=\"forestgreen\")) +\n  scale_color_manual(values=colors) +\n  scale_alpha_manual(values=c(\"plus\" = 1, \"minus\" = 1)) +\n  theme_bw() +\n  theme(plot.title = element_text(size=10, hjust=0.5), strip.background = element_rect(fill=NA))\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` instead.\n\n\nCode\nggsave(filename = file.path(figure_dir, \"example_high_q.pdf\"), \n       plot = p, width = 4, height = 8)\np + \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nClick to view more plots\n\n\n\nCode\ntest_df &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"train\") %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::group_by(TF) %&gt;%\n  slice_max(order_by=qValue, n=5) %&gt;%\n  select(Region, TF, qValue)\npurrr::walk(1:nrow(test_df), function(i) {\n  test_instance &lt;- unlist(test_df[i, ])\n  purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                 minus = -tf_counts[[tf]]$train$neg[match(test_instance[\"Region\"], seq_names$train), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  rbind(\n    tibble::tibble(position=-499:500, \n                   plus = ctrl_counts$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                   minus = -ctrl_counts$train$neg[match(test_instance[\"Region\"], seq_names$train), ],\n                   TF = \"Bias\", p_name = test_instance[\"Region\"])\n  ) %&gt;%\n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=name)) +\n  facet_wrap(~TF, scales=\"free_y\") +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=paste0(\"Peak \", test_instance[\"Region\"], \" | \", test_instance[\"TF\"], \n                    \" | \", test_instance[\"qValue\"])) -&gt; p\n  print(p)\n})"
  },
  {
    "objectID": "code/02_prepare_input.html#examples-random-peaks-with-bias",
    "href": "code/02_prepare_input.html#examples-random-peaks-with-bias",
    "title": "Prepare Input",
    "section": "9.2 Examples: Random Peaks with Bias",
    "text": "9.2 Examples: Random Peaks with Bias\n\n\nCode\ntest_instance &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"test\") %&gt;%\n  dplyr::filter(seqnames==\"chr1\", start &gt;= 4000, end &lt;= 100000000) %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::select(Region, TF, qValue) %&gt;%\n  .[1000, ]\nprint(test_instance)\n\n\n                     Region   TF   qValue\n1000 chr1:58392603-58393602 Oct4 21.10429\n\n\nCode\np &lt;- purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$test$pos[match(test_instance[\"Region\"], seq_names$test), ],\n                 minus = -tf_counts[[tf]]$test$neg[match(test_instance[\"Region\"], seq_names$test), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  rbind(\n    tibble::tibble(position=-499:500, \n                   plus = ctrl_counts$test$pos[match(test_instance[\"Region\"], seq_names$test), ],\n                   minus = -ctrl_counts$test$neg[match(test_instance[\"Region\"], seq_names$test), ],\n                   TF = \"patchcap\", p_name = test_instance[\"Region\"])\n  ) %&gt;%\n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  dplyr::mutate(TF = factor(TF, levels=names(colors))) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=TF, alpha=name), size=0.2) +\n  facet_wrap(~TF, ncol=1, scales=\"free_y\") +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=test_instance[\"Region\"]) +\n  #scale_color_manual(values=c(\"minus\"=\"darkred\", \"plus\"=\"forestgreen\")) +\n  scale_color_manual(values=colors) +\n  scale_alpha_manual(values=c(\"plus\" = 1, \"minus\" = 1)) +\n  theme_bw() +\n  theme(plot.title = element_text(size=10, hjust=0.5), strip.background = element_rect(fill=NA))\nggsave(filename = file.path(figure_dir, \"example_low_q.pdf\"), \n       plot = p, width = 4, height = 8)\np + \n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\n\n\nClick to view more plots\n\n\n\nCode\nset.seed(42)\ntest_df &lt;- peak_infos %&gt;%\n  as.data.frame() %&gt;%\n  dplyr::filter(set==\"train\") %&gt;%\n  dplyr::mutate(Region = paste0(seqnames, \":\", start, \"-\", end)) %&gt;%\n  dplyr::group_by(TF) %&gt;%\n  slice_sample(n=5) %&gt;%\n  select(Region, TF, qValue)\n\npurrr::walk(1:nrow(test_df), function(i) {\n  test_instance &lt;- unlist(test_df[i, ])\n  purrr::map_dfr(TFs, function(tf){\n  tibble::tibble(position=-499:500, \n                 plus = tf_counts[[tf]]$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                 minus = -tf_counts[[tf]]$train$neg[match(test_instance[\"Region\"], seq_names$train), ]) %&gt;%\n    dplyr::mutate(TF = tf, p_name = test_instance[\"Region\"])\n  }) %&gt;% \n  rbind(\n    tibble::tibble(position=-499:500, \n                   plus = ctrl_counts$train$pos[match(test_instance[\"Region\"], seq_names$train), ],\n                   minus = -ctrl_counts$train$neg[match(test_instance[\"Region\"], seq_names$train), ],\n                   TF = \"Bias\", p_name = test_instance[\"Region\"])\n  ) %&gt;%\n  pivot_longer(cols=c(minus, plus)) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, color=name)) +\n  facet_wrap(~TF, scales=\"free_y\") +\n  ggdark::dark_mode(verbose=FALSE) +\n  labs(x=\"Relative Position [bp]\", y=\"Counts\", color=\"Strand\", \n       title=paste0(\"Peak \", test_instance[\"Region\"], \" | \", test_instance[\"TF\"], \n                    \" | \", test_instance[\"qValue\"])) -&gt; p\n  print(p)\n})"
  },
  {
    "objectID": "code/02_prepare_input.html#from-raw-data",
    "href": "code/02_prepare_input.html#from-raw-data",
    "title": "Prepare Input",
    "section": "10.1 From Raw Data",
    "text": "10.1 From Raw Data\n\n\nCode\nroi &lt;- list(\"seqname\"=\"chr1\", \"start\"=180924752, \"end\"=180925152)\nTFs &lt;- c(\"Oct4\", \"Sox2\", \"Nanog\", \"Klf4\")\ndf &lt;-\n  purrr::map_dfr(TFs, function(tf) {\n    alignments &lt;- readGAlignments(file.path(data_dir, \"chip-nexus\", tf, \"pool_filt.bam\"),\n                                  param = ScanBamParam(which=GRanges(paste0(roi$seqname, \":\", roi$start, \"-\", roi$end))))\n    align_pos &lt;- alignments[strand(alignments)==\"+\"]\n    align_neg &lt;- alignments[strand(alignments)==\"-\"]\n\n    align_pos@cigar &lt;- rep(\"1M\", length(align_pos))\n    align_neg@start &lt;- GenomicAlignments::end(align_neg)\n    align_neg@cigar &lt;- rep(\"1M\", length(align_neg))\n\n    tibble::tibble(pos=as.numeric(coverage(align_pos)$chr1[roi$start:roi$end]),\n                   neg=-as.numeric(coverage(align_neg)$chr1[roi$start:roi$end]),\n                   position=roi$start:roi$end,\n                   TF=tf)\n  }) %&gt;%\n  pivot_longer(cols=c(\"pos\", \"neg\"))\ndf\n\n\n\n  \n\n\n\n\n\nCode\ndf %&gt;%\n  mutate(TF = factor(TF, levels=c(TFs))) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, col=name)) +\n  facet_wrap(~TF, ncol=1, scales=\"free_y\") +\n  labs(x=\"Position\", y=\"Counts\", col=\"Strand\") +\n  ggdark::dark_mode(verbose=FALSE)"
  },
  {
    "objectID": "code/02_prepare_input.html#from-processed-data",
    "href": "code/02_prepare_input.html#from-processed-data",
    "title": "Prepare Input",
    "section": "10.2 From Processed Data",
    "text": "10.2 From Processed Data\n\n\nCode\nroi &lt;- list(\"seqname\"=\"chr1\", \"start\"=180924752, \"end\"=180925152)\nroi_adjusted &lt;- roi\nroi_adjusted$start = roi_adjusted$start-1000\nroi_adjusted$end = roi_adjusted$end+1000\n\nTFs &lt;- c(\"Oct4\", \"Sox2\", \"Nanog\", \"Klf4\")\ndf2 &lt;- \n  purrr::map_dfr(TFs, function(tf) {\n    cov_list &lt;- list(\"pos\" = tf_counts[[tf]]$test$pos,\n                     \"neg\" = tf_counts[[tf]]$test$neg)\n    rnames &lt;- seq_names$test\n    gr_rnames &lt;- GRanges(rnames)\n    \n    bool_vec &lt;- \n      (as.character(gr_rnames@seqnames) == roi_adjusted$seqname &\n      start(gr_rnames@ranges) &gt;= roi_adjusted$start &\n      end(gr_rnames@ranges) &lt;= roi_adjusted$end)\n    \n    peak_index &lt;- which(bool_vec)[1]\n    peak_info &lt;- gr_rnames[peak_index]\n    \n    diff &lt;- 180924752 - start(peak_info@ranges) + 1\n    w &lt;- 400\n    \n    tibble::tibble(pos=cov_list$pos[peak_index, diff:(diff+w)],\n                   neg=-cov_list$neg[peak_index, diff:(diff+w)],\n                   position=0:400,\n                   TF=tf)\n}) %&gt;%\n  pivot_longer(cols=c(\"pos\", \"neg\"))\ndf2\n\n\n\n  \n\n\n\n\n\nCode\ndf2 %&gt;%\n  mutate(TF = factor(TF, levels=c(TFs))) %&gt;%\n  ggplot() +\n  geom_line(aes(x=position, y=value, col=name)) +\n  facet_wrap(~TF, ncol=1, scales=\"free_y\") +\n  labs(x=\"Position\", y=\"Counts\", col=\"Strand\") +\n  ggdark::dark_mode(verbose=FALSE)\n\n\n\n\n\n\n\n\n\nCompare.\n\n\nCode\nall(df2$value == df$value)\n\n\n[1] TRUE\n\n\nCode\nall(df2$TF == df$TF)\n\n\n[1] TRUE\n\n\nCode\nall(df2$name == df$name)\n\n\n[1] TRUE"
  },
  {
    "objectID": "code/02_prepare_input.html#save-image",
    "href": "code/02_prepare_input.html#save-image",
    "title": "Prepare Input",
    "section": "12.1 Save Image",
    "text": "12.1 Save Image\n\n\nCode\nsave.image(file.path(output_dir, \"tmp.RData\"))"
  },
  {
    "objectID": "code/02_prepare_input.html#session-info",
    "href": "code/02_prepare_input.html#session-info",
    "title": "Prepare Input",
    "section": "12.2 Session Info",
    "text": "12.2 Session Info\n\n\nCode\nsessionInfo()\n\n\nR version 4.2.3 (2023-03-15)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] C\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] plyranges_1.18.0                   TFBSTools_1.36.0                  \n [3] JASPAR2020_0.99.10                 motifmatchr_1.20.0                \n [5] furrr_0.3.1                        future_1.34.0                     \n [7] lubridate_1.9.3                    forcats_1.0.0                     \n [9] stringr_1.5.1                      dplyr_1.1.4                       \n[11] purrr_1.0.2                        readr_2.1.5                       \n[13] tidyr_1.3.1                        tibble_3.2.1                      \n[15] ggplot2_3.5.1                      tidyverse_2.0.0                   \n[17] BSgenome.Mmusculus.UCSC.mm10_1.4.3 BSgenome_1.66.3                   \n[19] BRGenomics_1.10.0                  GenomicAlignments_1.34.1          \n[21] Rsamtools_2.14.0                   Biostrings_2.66.0                 \n[23] XVector_0.38.0                     SummarizedExperiment_1.28.0       \n[25] Biobase_2.58.0                     MatrixGenerics_1.10.0             \n[27] matrixStats_1.4.1                  rtracklayer_1.58.0                \n[29] GenomicRanges_1.50.2               GenomeInfoDb_1.34.9               \n[31] IRanges_2.32.0                     S4Vectors_0.36.2                  \n[33] BiocGenerics_0.44.0                reticulate_1.40.0                 \n\nloaded via a namespace (and not attached):\n [1] colorspace_2.1-1            rjson_0.2.23               \n [3] rprojroot_2.0.4             farver_2.1.2               \n [5] listenv_0.9.1               bit64_4.5.2                \n [7] AnnotationDbi_1.60.2        fansi_1.0.6                \n [9] codetools_0.2-20            R.methodsS3_1.8.2          \n[11] cachem_1.1.0                geneplotter_1.76.0         \n[13] knitr_1.49                  jsonlite_1.8.9             \n[15] seqLogo_1.64.0              annotate_1.76.0            \n[17] GO.db_3.16.0                png_0.1-8                  \n[19] R.oo_1.27.0                 compiler_4.2.3             \n[21] httr_1.4.7                  Matrix_1.6-5               \n[23] fastmap_1.2.0               cli_3.6.3                  \n[25] htmltools_0.5.8.1           tools_4.2.3                \n[27] gtable_0.3.6                glue_1.8.0                 \n[29] TFMPvalue_0.0.9             GenomeInfoDbData_1.2.9     \n[31] reshape2_1.4.4              Rcpp_1.0.13-1              \n[33] vctrs_0.6.5                 ggdark_0.2.1               \n[35] xfun_0.49                   CNEr_1.34.0                \n[37] globals_0.16.3              timechange_0.3.0           \n[39] lifecycle_1.0.4             restfulr_0.0.15            \n[41] poweRlaw_0.80.0             gtools_3.9.5               \n[43] XML_3.99-0.17               zlibbioc_1.44.0            \n[45] scales_1.3.0                ragg_1.3.2                 \n[47] hms_1.1.3                   parallel_4.2.3             \n[49] RColorBrewer_1.1-3          yaml_2.3.10                \n[51] memoise_2.0.1               stringi_1.8.4              \n[53] RSQLite_2.3.9               BiocIO_1.8.0               \n[55] caTools_1.18.3              BiocParallel_1.32.6        \n[57] systemfonts_1.1.0           rlang_1.1.4                \n[59] pkgconfig_2.0.3             bitops_1.0-9               \n[61] pracma_2.4.4                evaluate_1.0.1             \n[63] lattice_0.22-6              htmlwidgets_1.6.4          \n[65] labeling_0.4.3              bit_4.5.0.1                \n[67] tidyselect_1.2.1            here_1.0.1                 \n[69] parallelly_1.40.1           plyr_1.8.9                 \n[71] magrittr_2.0.3              DESeq2_1.38.3              \n[73] R6_2.5.1                    generics_0.1.3             \n[75] DelayedArray_0.24.0         DBI_1.2.3                  \n[77] pillar_1.9.0                withr_3.0.2                \n[79] KEGGREST_1.38.0             RCurl_1.98-1.14            \n[81] crayon_1.5.3                utf8_1.2.4                 \n[83] tzdb_0.4.0                  rmarkdown_2.29             \n[85] locfit_1.5-9.10             grid_4.2.3                 \n[87] blob_1.2.4                  digest_0.6.37              \n[89] xtable_1.8-4                textshaping_0.4.0          \n[91] R.utils_2.12.3              munsell_0.5.1              \n[93] DirichletMultinomial_1.40.0"
  },
  {
    "objectID": "code/01_download.html",
    "href": "code/01_download.html",
    "title": "Data Download",
    "section": "",
    "text": "We can downlaod the data from https://zenodo.org/records/3371216\n\n\n\nCode\nimport requests\nfrom pathlib import Path\nimport tarfile\n\ndata_tar = Path(\"..\") / \"data.tar.gz\"\ndata_directory = Path(\"..\") / \"data\"\n\nif data_directory.exists():\n    print(f\"Data directory already exists at {data_directory}.\")\nelif data_tar.exists():\n    print(f\"Tar.gz file found at {data_tar}. Extracting...\")\n    with tarfile.open(data_tar, \"r:gz\") as tar_ref:\n        tar_ref.extractall(data_directory)\n    print(\"Extraction complete.\")\n    # Delete the tar file\n    data_tar.unlink()\n    print(f\"Deleted tar.gz file at {data_tar}.\")\nelse:\n    data_url = \"https://zenodo.org/records/3371216/files/data.tar.gz?download=1\"\n    response = requests.get(data_url, stream=True)\n    response.raise_for_status()  # Raise an error for bad HT\n    with open(data_tar, \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=8192):\n            file.write(chunk)\n    print(f\"Downloaded and saved tar.gz file at {data_tar}.\")\n    print(\"Extracting the tar.gz file...\")\n    with tarfile.open(data_tar, \"r:gz\") as tar_ref:\n        tar_ref.extractall(data_directory)\n    print(\"Extraction complete.\")\n    data_tar.unlink()\n    print(f\"Deleted tar.gz file at {data_tar}.\")\nlist(data_directory.iterdir())\n\n\nData directory already exists at ../data.\n\n\n[PosixPath('../data/mm10.blacklist.bed.gz'),\n PosixPath('../data/mm10.filtered.info'),\n PosixPath('../data/.DS_Store'),\n PosixPath('../data/intersected_set'),\n PosixPath('../data/mm10_no_alt_analysis_set_ENCODE.fasta.fai'),\n PosixPath('../data/mm10.fa.gz'),\n PosixPath('../data/fastas'),\n PosixPath('../data/chip-seq'),\n PosixPath('../data/mm10.blacklist.bed'),\n PosixPath('../data/merged_set'),\n PosixPath('../data/.gitignore'),\n PosixPath('../data/chip-nexus'),\n PosixPath('../data/mm10_no_alt_analysis_set_ENCODE.fasta'),\n PosixPath('../data/mm10.chrom.sizes')]\n\n\n\nSince the data directory is quite large we will delete the files we don’t need.\nFurthermore we download the mm10.fa file\n\n\n\nCode\nmm10_file = data_directory / \"mm10.fa.gz\"\nmm10_url = \"https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/mm10.fa.gz\"\n# Check if the file already exists\nif mm10_file.exists():\n    print(f\"File already exists at {mm10_file}. Skipping download.\")\nelse:\n    # Download the file\n    print(f\"Downloading {mm10_url}...\")\n    response = requests.get(mm10_url, stream=True)\n    response.raise_for_status()  # Raise an error for bad HTTP responses\n\n    # Save the file\n    with open(mm10_file, \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=8192):\n            file.write(chunk)\n    print(f\"Downloaded and saved file at {mm10_file}.\")\n\n\nFile already exists at ../data/mm10.fa.gz. Skipping download."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "1 TOC\n\nIntroduction\nData Download\nData Preprocessing\nAPI"
  },
  {
    "objectID": "code/00_introduction.html",
    "href": "code/00_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "1 TODO\nWhat data do we have, what are we predicting and why are we doing that?\n\n\n2 What\n\n\nNotes:\n\nActually they used an adaption of ChIP-seq called ChIP-seq Nexus which comprises an additional exonuclease step yielding an increased resolution."
  },
  {
    "objectID": "code/03_APIs.html",
    "href": "code/03_APIs.html",
    "title": "02 Dataset and NN Architecture API",
    "section": "",
    "text": "Here we document our dataset API as well as our neural network architecture API"
  },
  {
    "objectID": "code/03_APIs.html#example-1-create-train-dataset-for-all-tfs",
    "href": "code/03_APIs.html#example-1-create-train-dataset-for-all-tfs",
    "title": "02 Dataset and NN Architecture API",
    "section": "3.1 Example 1: Create Train Dataset for all TFs",
    "text": "3.1 Example 1: Create Train Dataset for all TFs\nOne has to provide the set which must be one of “train”, “tune”, “test” as well as the input directory and the list of TFs one wants to model.\n\n\nCode\nwhole_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=PRC_DIR, \n                                   TF_list=['Sox2', 'Oct4', 'Klf4', 'Nanog'])\nwhole_dataset\n\n\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2', 'Oct4', 'Klf4', 'Nanog']\nSize: 93904\n\n\nCheck the shapes via the check_shapes() method.\n\n\nCode\nwhole_dataset.check_shapes()\n\n\nself.tf_list=['Sox2', 'Oct4', 'Klf4', 'Nanog']\nself.one_hot_seqs.shape=(93904, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(93904, 4, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(93904, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(93904, 2, 1000) [idx, strand, pwidth]"
  },
  {
    "objectID": "code/03_APIs.html#example-2-create-train-dataset-for-sox2",
    "href": "code/03_APIs.html#example-2-create-train-dataset-for-sox2",
    "title": "02 Dataset and NN Architecture API",
    "section": "3.2 Example 2: Create Train Dataset for Sox2",
    "text": "3.2 Example 2: Create Train Dataset for Sox2\nIf we only want to take one or a few TFs into consideration we can specify which ones using the TF_list parameter. The constructor method will take care of everything and only keep the peaks that are specific to the TFs in the TF_list.\n\n\nCode\nsmall_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=PRC_DIR, \n                                   TF_list=['Sox2'])\nsmall_dataset\n\n\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 6748\n\n\n\n\nCode\nsmall_dataset.check_shapes()\n\n\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(6748, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(6748, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(6748, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(6748, 2, 1000) [idx, strand, pwidth]"
  },
  {
    "objectID": "code/03_APIs.html#example-3-create-train-dataset-for-sox2-and-high-confidence-peaks",
    "href": "code/03_APIs.html#example-3-create-train-dataset-for-sox2-and-high-confidence-peaks",
    "title": "02 Dataset and NN Architecture API",
    "section": "3.3 Example 3: Create Train Dataset for Sox2 and High-Confidence Peaks",
    "text": "3.3 Example 3: Create Train Dataset for Sox2 and High-Confidence Peaks\nWe might also want to filter peaks based on the qValue.\n\n\nCode\ncutoff = 4.5\nsns.histplot(np.log2(small_dataset.region_info.qValue))\nplt.xlabel(\"Log2 qValue\")\nplt.title(\"Distribution of qValues\")\nplt.axvline(cutoff, color=\"red\")\nplt.show()\n\n\n\n\n\n\n\n\n\nLooking at the histogram of the log2 qValue, we might decide to only keep peaks with a log2 qValue above 4.5.\n\n\nCode\nhighconf_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                      input_dir=PRC_DIR, \n                                      TF_list=[\"Sox2\"],\n                                      qval_thr=2**cutoff)\nhighconf_dataset\n\n\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 4182\n\n\n\n\nCode\nhighconf_dataset.check_shapes()\n\n\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(4182, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(4182, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(4182, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(4182, 2, 1000) [idx, strand, pwidth]"
  },
  {
    "objectID": "code/03_APIs.html#example-4-create-train-dataset-for-sox2-but-keep-all-regions",
    "href": "code/03_APIs.html#example-4-create-train-dataset-for-sox2-but-keep-all-regions",
    "title": "02 Dataset and NN Architecture API",
    "section": "3.4 Example 4: Create Train Dataset for Sox2 but keep all Regions",
    "text": "3.4 Example 4: Create Train Dataset for Sox2 but keep all Regions\nNow we might also want to create a training set that contains all the regions but only the counts for Sox2.\n\n\nCode\nsox2_all_regions = ChIP_Nexus_Dataset(set_name=\"train\", \n                                      input_dir=PRC_DIR, \n                                      TF_list=[\"Sox2\"], \n                                      subset=False)\nsox2_all_regions\n\n\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 93904\n\n\n\n\nCode\nsox2_all_regions.check_shapes()\n\n\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(93904, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(93904, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(93904, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(93904, 2, 1000) [idx, strand, pwidth]"
  },
  {
    "objectID": "code/03_APIs.html#example-1-one-tf-shape-prediction-no-bias-track",
    "href": "code/03_APIs.html#example-1-one-tf-shape-prediction-no-bias-track",
    "title": "02 Dataset and NN Architecture API",
    "section": "4.1 Example 1: One TF, Shape Prediction, No Bias Track",
    "text": "4.1 Example 1: One TF, Shape Prediction, No Bias Track\n\n\nCode\nmodel_1 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], \n                pred_total=False, bias_track=False)\nmodel_1\n\n\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n)"
  },
  {
    "objectID": "code/03_APIs.html#example-2-one-tf-shape-total-counts-prediction-no-bias-track",
    "href": "code/03_APIs.html#example-2-one-tf-shape-total-counts-prediction-no-bias-track",
    "title": "02 Dataset and NN Architecture API",
    "section": "4.2 Example 2: One TF, Shape & Total Counts Prediction, No Bias Track",
    "text": "4.2 Example 2: One TF, Shape & Total Counts Prediction, No Bias Track\n\n\nCode\nmodel_2 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], pred_total=True, bias_track=False)\nmodel_2\n\n\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0): TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)"
  },
  {
    "objectID": "code/03_APIs.html#example-3-one-tf-shape-total-counts-prediction-bias",
    "href": "code/03_APIs.html#example-3-one-tf-shape-total-counts-prediction-bias",
    "title": "02 Dataset and NN Architecture API",
    "section": "4.3 Example 3: One TF, Shape & Total Counts Prediction, Bias",
    "text": "4.3 Example 3: One TF, Shape & Total Counts Prediction, Bias\n\n\nCode\nmodel_3 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], pred_total=True, bias_track=True)\nmodel_3\n\n\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0): TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)\n\n\nFeatures bias weights.\n\n\nCode\nmodel_3.profile_heads[0].bias_weights\n\n\nParameter containing:\ntensor([0.0100, 0.0100], requires_grad=True)"
  },
  {
    "objectID": "code/03_APIs.html#example-4-all-tfs-shape-total-counts-prediction-bias",
    "href": "code/03_APIs.html#example-4-all-tfs-shape-total-counts-prediction-bias",
    "title": "02 Dataset and NN Architecture API",
    "section": "4.4 Example 4: All TFs, Shape & Total Counts Prediction, Bias",
    "text": "4.4 Example 4: All TFs, Shape & Total Counts Prediction, Bias\n\n\nCode\nmodel_4 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\", \"Oct4\", \"Nanog\", \"Klf4\"], pred_total=True, bias_track=True)\nmodel_4\n\n\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0-3): 4 x ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0-3): 4 x TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)"
  },
  {
    "objectID": "code/03_APIs.html#recreate-figure-1-e",
    "href": "code/03_APIs.html#recreate-figure-1-e",
    "title": "02 Dataset and NN Architecture API",
    "section": "5.1 Recreate Figure 1 e",
    "text": "5.1 Recreate Figure 1 e\n\n\nCode\ntest_dataset = ChIP_Nexus_Dataset(set_name=\"test\", \n                                  input_dir=PRC_DIR, \n                                  TF_list=['Oct4', 'Sox2', 'Nanog', 'Klf4'])\ntest_dataset\n\n\nChIP_Nexus_Dataset\nSet: test\nTFs: ['Oct4', 'Sox2', 'Nanog', 'Klf4']\nSize: 27727\n\n\n\n\nCode\ntmp_df = test_dataset.region_info.copy().reset_index()\nidx = tmp_df.loc[(tmp_df.seqnames==\"chr1\") & (tmp_df.start &gt; 180924752-1000) & (tmp_df.end &lt; 180925152+1000)].index.to_numpy()[0]\n\ndiff = 180924752 - tmp_df.start[idx] + 1\nw = 400\n\nfig, axis = plt.subplots(4, 1, figsize=(6, 14))\n\nfor ax, (i, tf) in zip(axis, enumerate(test_dataset.tf_list)):\n  ax.plot(test_dataset.tf_counts[idx, i, 0, diff:(diff+w)], label=\"pos\")\n  ax.plot(-test_dataset.tf_counts[idx, i, 1, diff:(diff+w)], label=\"neg\")\n  ax.legend()\n  ax.set_title(tf)\nplt.show()"
  },
  {
    "objectID": "code/03_APIs.html#check-one-hot-encoding",
    "href": "code/03_APIs.html#check-one-hot-encoding",
    "title": "02 Dataset and NN Architecture API",
    "section": "5.2 Check One-Hot Encoding",
    "text": "5.2 Check One-Hot Encoding\nTo check whether the one-hot encoding worked as expected, we compare here:\n\nThe one-hot encoded sequence as stored in the test dataset\n\n\n\nCode\nplt.imshow(test_dataset.one_hot_seqs[idx, :, diff:(diff+w)], interpolation=\"none\", aspect=\"auto\")\nplt.title(\"One-Hot Encoding from Test Dataset\")\nplt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe one-hot encoded sequence obtained from reading in the mm10 genome and one-hot encoding corresponding sequence\n\n\n\nCode\n#from Bio.Seq import Seq\n#from Bio import SeqIO\n#mm10_ref = SeqIO.to_dict(SeqIO.parse(DATA_DIR / \"mm10.fa\", \"fasta\"))\n#seq = mm10_ref[tmp_df.iloc[idx][\"seqnames\"]][180924752:180925152]\n#one_hot_seq = np.zeros((4, 400))\n#for i, letter in enumerate(np.array(seq.seq)):\n#  if letter==\"A\": one_hot_seq[0, i] = 1\n#  if letter==\"C\": one_hot_seq[1, i] = 1\n#  if letter==\"G\": one_hot_seq[2, i] = 1\n#  if letter==\"T\": one_hot_seq[3, i] = 1\n#plt.imshow(one_hot_seq, interpolation=\"none\", aspect=\"auto\")\n#plt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\n#plt.title(\"One-Hot Encoding based on Reference Sequence\")\n#plt.show()\n\n\n\n\nCode\nimport gzip\nfrom Bio.Seq import Seq\nfrom Bio import SeqIO\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata_dir = Path(\"..\") / \"data\"\nmm10_path = data_dir / \"mm10.fa.gz\"\n\n# Parse the gzipped file on-the-fly\nwith gzip.open(mm10_path, \"rt\") as handle:\n    mm10_ref = SeqIO.to_dict(SeqIO.parse(handle, \"fasta\"))\nseq = mm10_ref[tmp_df[\"seqnames\"][idx]].seq[180924752:180925152]\n\none_hot_seq = np.zeros((4, len(seq)))\nfor i, letter in enumerate(seq):\n    if letter == \"A\": one_hot_seq[0, i] = 1\n    elif letter == \"C\": one_hot_seq[1, i] = 1\n    elif letter == \"G\": one_hot_seq[2, i] = 1\n    elif letter == \"T\": one_hot_seq[3, i] = 1\n\nplt.imshow(one_hot_seq, interpolation=\"none\", aspect=\"auto\")\nplt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\nplt.title(\"One-Hot Encoding based on Reference Sequence\")\nplt.xlabel(\"Position\")\nplt.ylabel(\"Base\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfor the peak seen in Figure 1e\n\n\nCode\nnp.all(test_dataset.one_hot_seqs[idx, :, diff:(diff+w)] == one_hot_seq)\n\n\nnp.True_\n\n\nAnd we see that we get exactly the same."
  }
]