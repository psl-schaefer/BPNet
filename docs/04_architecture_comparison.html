<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Comparing different number of dilated convolutional layers, different number of channels in each dilated convolutational layer, and different kernel sizes for the first layer.">

<title>BPNet - 04 Architecture Comparisons</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">BPNet</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./00_introduction.html">Introduction</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./01_prepare_input.html">Data Processing</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./02_APIs.html">APIs</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./03_training.html">Training</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./04_architecture_comparison.html" aria-current="page">Architectures</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./05_interpretability.qmd">Interpretability</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./06_mutagenesis.qmd">Mutagenesis</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#train-parameters" id="toc-train-parameters" class="nav-link active" data-scroll-target="#train-parameters"><span class="toc-section-number">1</span>  Train Parameters</a></li>
  <li><a href="#libraries" id="toc-libraries" class="nav-link" data-scroll-target="#libraries"><span class="toc-section-number">2</span>  Libraries</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="toc-section-number">3</span>  Data</a></li>
  <li><a href="#different-number-of-dilated-convolutational-layers" id="toc-different-number-of-dilated-convolutational-layers" class="nav-link" data-scroll-target="#different-number-of-dilated-convolutational-layers"><span class="toc-section-number">4</span>  Different Number of Dilated Convolutational Layers</a>
  <ul class="collapse">
  <li><a href="#training-only-shape-prediction" id="toc-training-only-shape-prediction" class="nav-link" data-scroll-target="#training-only-shape-prediction"><span class="toc-section-number">4.1</span>  Training (Only Shape Prediction)</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation"><span class="toc-section-number">4.2</span>  Evaluation</a></li>
  </ul></li>
  <li><a href="#different-number-of-dilated-convolutational-layers-1" id="toc-different-number-of-dilated-convolutational-layers-1" class="nav-link" data-scroll-target="#different-number-of-dilated-convolutational-layers-1"><span class="toc-section-number">5</span>  Different Number of Dilated Convolutational Layers</a>
  <ul class="collapse">
  <li><a href="#training-only-shape-prediction-1" id="toc-training-only-shape-prediction-1" class="nav-link" data-scroll-target="#training-only-shape-prediction-1"><span class="toc-section-number">5.1</span>  Training (Only Shape Prediction)</a></li>
  <li><a href="#evaluation-1" id="toc-evaluation-1" class="nav-link" data-scroll-target="#evaluation-1"><span class="toc-section-number">5.2</span>  Evaluation</a></li>
  </ul></li>
  <li><a href="#different-sizes-of-the-first-kernel" id="toc-different-sizes-of-the-first-kernel" class="nav-link" data-scroll-target="#different-sizes-of-the-first-kernel"><span class="toc-section-number">6</span>  Different Sizes of the first Kernel</a>
  <ul class="collapse">
  <li><a href="#training-only-shape-prediction-2" id="toc-training-only-shape-prediction-2" class="nav-link" data-scroll-target="#training-only-shape-prediction-2"><span class="toc-section-number">6.1</span>  Training (Only Shape Prediction)</a></li>
  <li><a href="#evaluation-2" id="toc-evaluation-2" class="nav-link" data-scroll-target="#evaluation-2"><span class="toc-section-number">6.2</span>  Evaluation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">04 Architecture Comparisons</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source" data-quarto-source-url="repo"><i class="bi"></i> Code</button></div></div>
</div>

<div>
  <div class="description">
    Comparing different number of dilated convolutional layers, different number of channels in each dilated convolutational layer, and different kernel sizes for the first layer.
  </div>
</div>


<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="train-parameters" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Train Parameters</h1>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>TF_LIST <span class="op">=</span> [<span class="st">"Nanog"</span>, <span class="st">"Klf4"</span>, <span class="st">"Oct4"</span>, <span class="st">"Sox2"</span>]</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>INPUT_DIR <span class="op">=</span> <span class="st">"/home/philipp/BPNet/input/"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>ALPHA <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>MAX_EPOCHS <span class="op">=</span> <span class="dv">100</span>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>EARLY_STOP_PATIENCE <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>RESTORE_BEST_WEIGHTS <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plot_while_train <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>retrain_conv_layers <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>retrain_channel <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>retrain_kern_size <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="libraries" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Libraries</h1>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'dark_background'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.architectures <span class="im">import</span> BPNet</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.utils <span class="im">import</span> ChIP_Nexus_Dataset, dummy_shape_predictions, dummy_total_counts_predictions</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.loss <span class="im">import</span> neg_log_multinomial</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.metrics <span class="im">import</span> permute_array, bin_max_values, bin_counts_amb, binary_labels_from_counts, compute_auprc_bins</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>color_pal <span class="op">=</span> {<span class="st">"Oct4"</span>: <span class="st">"#CD5C5C"</span>, <span class="st">"Sox2"</span>: <span class="st">"#849EEB"</span>, <span class="st">"Nanog"</span>: <span class="st">"#FFE03F"</span>, <span class="st">"Klf4"</span>: <span class="st">"#92C592"</span>, <span class="st">"patchcap"</span>: <span class="st">"#827F81"</span>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.metrics <span class="im">as</span> skm</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using cuda device</code></pre>
</div>
</div>
</section>
<section id="data" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Data</h1>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"train"</span>, </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                                   input_dir<span class="op">=</span>INPUT_DIR, </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                                   TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>train_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>ChIP_Nexus_Dataset
Set: train
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 93904</code></pre>
</div>
</div>
<p>Determine <span class="math inline">\(\lambda\)</span> hyperparameter</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>lambda_param <span class="op">=</span> (np.median(train_dataset.tf_counts.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>), axis<span class="op">=</span><span class="dv">0</span>)).mean() <span class="op">/</span> <span class="dv">10</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>lambda_param</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>11.7375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>dummy_shape_predictions(train_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unfiform Prediction Loss:   490.46
Mean Prediction Loss:       438.73
Perfect Prediction Loss:    133.78</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>dummy_total_counts_predictions(train_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Prediction Loss:       0.71
Perfect Prediction Loss:    0.00</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>tune_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"tune"</span>, </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span>INPUT_DIR, </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>tune_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>ChIP_Nexus_Dataset
Set: tune
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 29277</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>dummy_shape_predictions(tune_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unfiform Prediction Loss:   494.43
Mean Prediction Loss:       442.46
Perfect Prediction Loss:    135.56</code></pre>
</div>
</div>
</section>
<section id="different-number-of-dilated-convolutational-layers" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Different Number of Dilated Convolutational Layers</h1>
<section id="training-only-shape-prediction" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="training-only-shape-prediction"><span class="header-section-number">4.1</span> Training (Only Shape Prediction)</h2>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>n_layers_list <span class="op">=</span> np.arange(<span class="dv">1</span>,<span class="dv">16</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> retrain_conv_layers:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n_layers <span class="kw">in</span> n_layers_list:</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> BPNet(n_dil_layers<span class="op">=</span>n_layers, TF_list<span class="op">=</span>TF_LIST, pred_total<span class="op">=</span><span class="va">False</span>, bias_track<span class="op">=</span><span class="va">True</span>).to(device)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="dv">4</span><span class="op">*</span><span class="fl">1e-4</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    tune_loader<span class="op">=</span>DataLoader(tune_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    train_loss, test_loss <span class="op">=</span> [], []</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(MAX_EPOCHS):</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>      model.train()</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>      train_loss_epoch <span class="op">=</span> []</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> train_loader:</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch.append(loss.item())</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>      train_loss.append(<span class="bu">sum</span>(train_loss_epoch)<span class="op">/</span><span class="bu">len</span>(train_loss_epoch))</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># evaluation part</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>      test_loss_epoch <span class="op">=</span> []</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> tune_loader:</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>              one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>              profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>              test_loss_epoch.append(loss.item())</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>          test_loss.append(<span class="bu">sum</span>(test_loss_epoch)<span class="op">/</span><span class="bu">len</span>(test_loss_epoch))</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> test_loss[<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> np.array(test_loss).<span class="bu">min</span>():</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>        best_state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> patience_counter <span class="op">==</span> EARLY_STOP_PATIENCE:</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> RESTORE_BEST_WEIGHTS:</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>      model.load_state_dict(best_state_dict)</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot train and test loss</span></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(train_loss), label<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(test_loss), label<span class="op">=</span><span class="st">"test"</span>)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save the model</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>    torch.save(obj<span class="op">=</span>model, f<span class="op">=</span><span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>n_layers<span class="sc">}</span><span class="ss">_dil_layers_model.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluation" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="evaluation"><span class="header-section-number">4.2</span> Evaluation</h2>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"test"</span>, </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span>INPUT_DIR, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>ChIP_Nexus_Dataset
Set: test
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 27727</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>save_scores <span class="op">=</span> []</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>true_counts <span class="op">=</span> test_dataset.tf_counts.copy()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> n_layers_list:</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> torch.load(<span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">_dil_layers_model.pt"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make predictions</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  pred <span class="op">=</span> torch.zeros(test_dataset.tf_counts.shape, dtype<span class="op">=</span>torch.float32).to(device)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> batch_idx, data <span class="kw">in</span> <span class="bu">enumerate</span>(test_dataloader):</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> data</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>          profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>          pred[batch_idx, :, :, :] <span class="op">=</span> profile_pred</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  all_pred <span class="op">=</span> pred.cpu().numpy().copy()</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span> np.allclose(all_pred.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>), <span class="dv">1</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, tf <span class="kw">in</span> <span class="bu">enumerate</span>(TF_LIST): <span class="co"># loop over the four TFs</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>      pred_tf <span class="op">=</span> all_pred[:, i, :, :]</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>      counts_tf <span class="op">=</span> true_counts[:, i, :, :]</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>      labels, predictions, random <span class="op">=</span> binary_labels_from_counts(counts_tf, pred_tf)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>      auprc_score <span class="op">=</span> skm.average_precision_score(labels, predictions)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>      save_scores.append({<span class="st">"tf"</span>: tf,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"n_layers"</span>:n,</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"auprc"</span>: auprc_score})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(save_scores)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"/home/philipp/BPNet/out/dil_layers_auprc.csv"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"n_layers"</span>, y<span class="op">=</span><span class="st">"auprc"</span>, hue<span class="op">=</span><span class="st">"tf"</span>, palette<span class="op">=</span>color_pal)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_architecture_comparison_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="different-number-of-dilated-convolutational-layers-1" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Different Number of Dilated Convolutational Layers</h1>
<section id="training-only-shape-prediction-1" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="training-only-shape-prediction-1"><span class="header-section-number">5.1</span> Training (Only Shape Prediction)</h2>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>n_channel_list <span class="op">=</span> np.array([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> retrain_channel:</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n_channel <span class="kw">in</span> n_channel_list:</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> BPNet(n_dil_layers<span class="op">=</span><span class="dv">9</span>, TF_list<span class="op">=</span>TF_LIST, pred_total<span class="op">=</span><span class="va">False</span>, bias_track<span class="op">=</span><span class="va">True</span>, conv_channels<span class="op">=</span>n_channel).to(device)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="dv">4</span><span class="op">*</span><span class="fl">1e-4</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    tune_loader<span class="op">=</span>DataLoader(tune_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    train_loss, test_loss <span class="op">=</span> [], []</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(MAX_EPOCHS):</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>      model.train()</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>      train_loss_epoch <span class="op">=</span> []</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> train_loader:</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>        profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch.append(loss.item())</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>      train_loss.append(<span class="bu">sum</span>(train_loss_epoch)<span class="op">/</span><span class="bu">len</span>(train_loss_epoch))</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># evaluation part</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>      test_loss_epoch <span class="op">=</span> []</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> tune_loader:</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>              one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>              profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>              test_loss_epoch.append(loss.item())</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>          test_loss.append(<span class="bu">sum</span>(test_loss_epoch)<span class="op">/</span><span class="bu">len</span>(test_loss_epoch))</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> test_loss[<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> np.array(test_loss).<span class="bu">min</span>():</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>        best_state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> patience_counter <span class="op">==</span> EARLY_STOP_PATIENCE:</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> RESTORE_BEST_WEIGHTS:</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>      model.load_state_dict(best_state_dict)</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot train and test loss</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(train_loss), label<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(test_loss), label<span class="op">=</span><span class="st">"test"</span>)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save the model</span></span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>    torch.save(obj<span class="op">=</span>model, f<span class="op">=</span><span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>n_channel<span class="sc">}</span><span class="ss">_conv_channel_model.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluation-1" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="evaluation-1"><span class="header-section-number">5.2</span> Evaluation</h2>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"test"</span>, </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span>INPUT_DIR, </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>ChIP_Nexus_Dataset
Set: test
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 27727</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>save_scores <span class="op">=</span> []</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>true_counts <span class="op">=</span> test_dataset.tf_counts.copy()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> n_channel_list:</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> torch.load(<span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">_conv_channel_model.pt"</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make predictions</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  pred <span class="op">=</span> torch.zeros(test_dataset.tf_counts.shape, dtype<span class="op">=</span>torch.float32).to(device)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> batch_idx, data <span class="kw">in</span> <span class="bu">enumerate</span>(test_dataloader):</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> data</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>          profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>          pred[batch_idx, :, :, :] <span class="op">=</span> profile_pred</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>  all_pred <span class="op">=</span> pred.cpu().numpy().copy()</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span> np.allclose(all_pred.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>), <span class="dv">1</span>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, tf <span class="kw">in</span> <span class="bu">enumerate</span>(TF_LIST): <span class="co"># loop over the four TFs</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>      pred_tf <span class="op">=</span> all_pred[:, i, :, :]</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>      counts_tf <span class="op">=</span> true_counts[:, i, :, :]</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>      labels, predictions, random <span class="op">=</span> binary_labels_from_counts(counts_tf, pred_tf)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>      auprc_score <span class="op">=</span> skm.average_precision_score(labels, predictions)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>      save_scores.append({<span class="st">"tf"</span>: tf,</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"n_channels"</span>:n,</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"auprc"</span>: auprc_score})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(save_scores)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"/home/philipp/BPNet/out/conv_channel_auprc.csv"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"n_channels"</span>, y<span class="op">=</span><span class="st">"auprc"</span>, hue<span class="op">=</span><span class="st">"tf"</span>, palette<span class="op">=</span>color_pal)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_architecture_comparison_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="different-sizes-of-the-first-kernel" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Different Sizes of the first Kernel</h1>
<section id="training-only-shape-prediction-2" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="training-only-shape-prediction-2"><span class="header-section-number">6.1</span> Training (Only Shape Prediction)</h2>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>kernel_sizes <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">9</span>, <span class="dv">13</span>, <span class="dv">17</span>, <span class="dv">21</span>, <span class="dv">25</span>, <span class="dv">29</span>, <span class="dv">33</span>, <span class="dv">37</span>])</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> retrain_kern_size:</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> kern_size <span class="kw">in</span> kernel_sizes:</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> BPNet(n_dil_layers<span class="op">=</span><span class="dv">9</span>, TF_list<span class="op">=</span>TF_LIST, pred_total<span class="op">=</span><span class="va">False</span>, bias_track<span class="op">=</span><span class="va">True</span>, conv_channels<span class="op">=</span><span class="dv">64</span>, size_first_kernel<span class="op">=</span>kern_size).to(device)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="dv">4</span><span class="op">*</span><span class="fl">1e-4</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    tune_loader<span class="op">=</span>DataLoader(tune_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    train_loss, test_loss <span class="op">=</span> [], []</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(MAX_EPOCHS):</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>      model.train()</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>      train_loss_epoch <span class="op">=</span> []</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> train_loader:</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>        one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch.append(loss.item())</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>      train_loss.append(<span class="bu">sum</span>(train_loss_epoch)<span class="op">/</span><span class="bu">len</span>(train_loss_epoch))</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># evaluation part</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>      test_loss_epoch <span class="op">=</span> []</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">with</span> torch.no_grad():</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="kw">in</span> tune_loader:</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>              one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>              profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> neg_log_multinomial(k_obs<span class="op">=</span>tf_counts, p_pred<span class="op">=</span>profile_pred, device<span class="op">=</span>device)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>              test_loss_epoch.append(loss.item())</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>          test_loss.append(<span class="bu">sum</span>(test_loss_epoch)<span class="op">/</span><span class="bu">len</span>(test_loss_epoch))</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> test_loss[<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> np.array(test_loss).<span class="bu">min</span>():</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>        best_state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> patience_counter <span class="op">==</span> EARLY_STOP_PATIENCE:</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> RESTORE_BEST_WEIGHTS:</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>      model.load_state_dict(best_state_dict)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot train and test loss</span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(train_loss), label<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.arange(epoch<span class="op">+</span><span class="dv">1</span>), np.array(test_loss), label<span class="op">=</span><span class="st">"test"</span>)</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save the model</span></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>    torch.save(obj<span class="op">=</span>model, f<span class="op">=</span><span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>kern_size<span class="sc">}</span><span class="ss">_first_kern_size_model.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluation-2" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="evaluation-2"><span class="header-section-number">6.2</span> Evaluation</h2>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"test"</span>, </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span>INPUT_DIR, </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>ChIP_Nexus_Dataset
Set: test
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 27727</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>save_scores <span class="op">=</span> []</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">0</span>, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>true_counts <span class="op">=</span> test_dataset.tf_counts.copy()</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> kernel_sizes:</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> torch.load(<span class="ss">f"/home/philipp/BPNet/trained_models/</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">_first_kern_size_model.pt"</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make predictions</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  pred <span class="op">=</span> torch.zeros(test_dataset.tf_counts.shape, dtype<span class="op">=</span>torch.float32).to(device)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> batch_idx, data <span class="kw">in</span> <span class="bu">enumerate</span>(test_dataloader):</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> data</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>          one_hot, tf_counts, ctrl_counts, ctrl_smooth <span class="op">=</span> one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>          profile_pred <span class="op">=</span> model.forward(sequence<span class="op">=</span>one_hot, bias_raw<span class="op">=</span>ctrl_counts, bias_smooth<span class="op">=</span>ctrl_smooth)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>          pred[batch_idx, :, :, :] <span class="op">=</span> profile_pred</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  all_pred <span class="op">=</span> pred.cpu().numpy().copy()</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">assert</span> np.allclose(all_pred.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>), <span class="dv">1</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, tf <span class="kw">in</span> <span class="bu">enumerate</span>(TF_LIST): <span class="co"># loop over the four TFs</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>      pred_tf <span class="op">=</span> all_pred[:, i, :, :]</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>      counts_tf <span class="op">=</span> true_counts[:, i, :, :]</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>      labels, predictions, random <span class="op">=</span> binary_labels_from_counts(counts_tf, pred_tf)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>      auprc_score <span class="op">=</span> skm.average_precision_score(labels, predictions)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>      save_scores.append({<span class="st">"tf"</span>: tf,</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"first_kern_size"</span>: n,</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"auprc"</span>: auprc_score})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(save_scores)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"/home/philipp/BPNet/out/first_kern_size_auprc.csv"</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"first_kern_size"</span>, y<span class="op">=</span><span class="st">"auprc"</span>, hue<span class="op">=</span><span class="st">"tf"</span>, palette<span class="op">=</span>color_pal)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_architecture_comparison_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>