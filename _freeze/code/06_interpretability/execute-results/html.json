{
  "hash": "f8ef1321b2b5a3e667fc4826fe11fee8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Interpretability\"\njupyter: py-env-bpnet\nexecute:\n  freeze: auto\n---\n\n\n# Description\n\n- Here we use Interpretable ML tools to make sense of the model predictions.\n\n# Libraries\n\n::: {#c082e442 .cell execution_count=1}\n``` {.python .cell-code}\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom captum.attr import DeepLift\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport modisco.visualization\nfrom modisco.visualization import viz_sequence\n\nfrom src.config import conf_dict\nfrom src.architectures import *\nfrom src.utils import * \nfrom src.loss import *\nfrom src.metrics import *\nfrom src.DeepLiftUtils import *\n\n# dark mode doesn't quite work for the attribution plots\n#plt.style.use('dark_background')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n```\n:::\n:::\n\n\n# Data\n\n::: {#215a8b11 .cell execution_count=2}\n``` {.python .cell-code}\n#conf_dict[\"tf_list\"] = [\"Nanog\"]\n#conf_dict[\"batch_size\"] = 248\n#conf_dict[\"max_epochs\"] = 25\n#conf_dict[\"early_stop_patience\"] = 4\n#conf_dict[\"restore_best_weights\"] = True\n\nPRC_DIR = Path(\"..\") / \"prc\"\nMODELS_DIR = Path(\"..\") / \"trained_models\"\nFIG_DIR = Path(\"..\") / \"figures\" / \"interpretability\"\nFIG_DIR.mkdir(exist_ok=True, parents=True)\n```\n:::\n\n\n::: {#ee085a4b .cell execution_count=3}\n``` {.python .cell-code}\nif torch.cuda.is_available():\n  device = \"cuda\"\nelif torch.backends.mps.is_available():\n  device = torch.device(\"mps\")\nelse:\n  decive = \"cpu\"\nprint(f\"Using {device} device\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing mps device\n```\n:::\n:::\n\n\n::: {#9a47506d .cell execution_count=4}\n``` {.python .cell-code}\ntrain_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=PRC_DIR, \n                                   TF_list=conf_dict[\"tf_list\"])\ntrain_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 93904\n```\n:::\n:::\n\n\n::: {#2f816508 .cell execution_count=5}\n``` {.python .cell-code}\ntune_dataset = ChIP_Nexus_Dataset(set_name=\"tune\", \n                                  input_dir=PRC_DIR, \n                                  TF_list=conf_dict[\"tf_list\"])\ntune_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nChIP_Nexus_Dataset\nSet: tune\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 29277\n```\n:::\n:::\n\n\n::: {#cf89dfff .cell execution_count=6}\n``` {.python .cell-code}\ntest_dataset = ChIP_Nexus_Dataset(set_name=\"test\", \n                                  input_dir=PRC_DIR, \n                                  TF_list=conf_dict[\"tf_list\"])\ntest_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nChIP_Nexus_Dataset\nSet: test\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 27727\n```\n:::\n:::\n\n\nFor interpretability methods like DeepLift (https://github.com/kundajelab/deeplift), integrated gradients or gradient x input, we require a scalar output. The BPNet model does, however, predict profiles shapes as tensors of size 2 x 1000 (strand x bps). For backpropagation or DeepLift we collapse the profile for each strand to one representative value, which can then be used to compute the gradient of this scalar with respect to each of the input bps. \n\nWe define our profile prediction as the softmax of the pre-activation of the last layer in our profile shape prediction head.\n\n$\\tilde{z}$ is the pre-activation of our last layer.\n\n$p = softmax(\\tilde{z}) = \\frac{\\exp{\\tilde{z}}}{\\sum_{i}^{N}{\\exp{\\tilde{z'}_i}}}$ with $N$ corresponding to the number of bps.\n\nWe weight the pre-activations of the last layer with the softmax of the same pre-activations and take the sum. This way we get one value for each strand.\n\n$z = \\sum_{i}^{N}{p_i * \\tilde{z}_i}$ with $z \\in \\mathbb{R}^{2}$\n\nImportantly, we have to detach the softmax activation so that it is a constant value during backpropagation of contribution scores or gradients.\n\nWhen computing DeepLift scores we  take the average of the two strands. \n\n::: {#e2cb3737 .cell execution_count=7}\n``` {.python .cell-code}\nmodel = torch.load(MODELS_DIR / \"all_tfs_model.pt\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/n8/xnf8qmpj41795tf723xy8mqm0000gn/T/ipykernel_94928/1827116589.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(MODELS_DIR / \"all_tfs_model.pt\")\n```\n:::\n:::\n\n\n# DeepLift\n\nWe picked some exemplary regions of interest from the paper (Fig.2 and Supp.Fig.2) to compute the contribution scores and make some plots.\n\n::: {#370661dd .cell execution_count=8}\n``` {.python .cell-code}\ndl = DeepLift(model)\n```\n:::\n\n\n::: {#117be393 .cell execution_count=9}\n``` {.python .cell-code}\ndef get_contr_region(seqname, start, end, dataset, model, dl, device, tf_list, output_dir, plot=True, figsize1=(20,2), figsize2=(10,1.5)):\n    \"\"\"Compute the DeepLift contribution scores for a 1kb sequence which contains the shorter \n    region of interest specified by the input arguments.\n    Params:\n        seq_name: string\n            specifies the chromosome \n        start: int\n            specifies start coordinate of sequence of interest on chromosome\n        end: int\n            specifies end coordinate of sequence of interest on chromsome\n        dataset: utils.ChIP_Nexus_Dataset object\n        device: cuda or cpu\n        tf_list: \n            Contains names of TFs for which we want to compute the contributions\n        plot: bool\n            Whether to visualize the DeepLift contribution scores.\n\n    Returns:\n        contr: tensor (4x1000)\n            Contains the contribution of each bp to the profile shape predictions for the input sequence.\n        dist_start: int\n            distance between the start of the 1kb sequence and the region of interest\n    \"\"\"\n    # select sequence of interest\n    tmp_df, idx, dist_start, one_hot, baseline, bias_raw, bias_smooth, tf_counts = get_seq_oi(seqname, start, end, dataset, device)\n    width = end - start\n\n    # compute contribution scores for each tf\n    contr_list = []\n    df_list = []\n    for tf_index, tf in enumerate(tf_list):\n        contr = dl.attribute(inputs=one_hot, baselines=baseline, target=(tf_index), additional_forward_args=(bias_raw, bias_smooth, True)).detach().cpu().numpy()\n        contr_list.append(contr)\n\n        pred, _ = model.forward(one_hot, bias_raw, bias_smooth, interpretation=False)\n        pred = pred.detach().cpu().numpy().squeeze()\n        # scale prediciton with total counts\n        pred = pred * tf_counts.sum(axis=-1, keepdims=True)\n        tf_df = pd.DataFrame({\"pos\": np.arange(width+1), \"TF\": tf, \"pos_values\": pred[tf_index, 0, dist_start : (dist_start + width+1)], \"neg_values\": pred[tf_index, 1, dist_start : (dist_start + width+1)]})\n        df_list.append(tf_df)\n\n        if plot:\n            # entire sequence original\n            plot_weights(contr,\n            fontsizes=[20,15,15],\n            title = f\"{tf} - 1kbp sequence\", \n            xlabel=f\"{tmp_df.seqnames[idx]}: {tmp_df.start[idx]}-{tmp_df.end[idx]}\", \n            ylabel=\"DeepLift contribution scores\",\n            subticks_frequency=20, figsize=figsize1)\n            plt.savefig(output_dir / f\"{tf}_{seqname}_{start}_{end}_entireSeq_DeepLift.pdf\")\n\n            # zoomed into motif region\n            plot_weights(contr[:, :,dist_start : (dist_start + width+1)],\n            fontsizes=[20,15,15],\n            title = f\"{tf} - Motif of interest\", \n            xlabel=f\"{seqname}: {start}-{end}, ({dist_start} - {dist_start + width+1})\", \n            ylabel=\"DeepLift contribution scores\",\n            subticks_frequency=10, figsize=figsize2)\n            plt.savefig(output_dir / f\"{tf}_{seqname}_{start}_{end}_zoomedSeq_DeepLift.pdf\")  \n            \n            # plot profiles\n            fig, axis = plt.subplots(1,2,figsize=(12,4))\n            axis[0].plot(tf_counts[tf_index, 0, :], label=\"true counts\", color=\"green\", linewidth=0.8)\n            axis[0].plot(-tf_counts[tf_index, 1, :], color=\"green\", linewidth=0.8)\n            axis[0].plot(pred[tf_index, 0, :], label=\"pred\", color=\"blue\", linewidth=0.8)\n            axis[0].plot(-pred[tf_index, 1, :], color=\"blue\", linewidth=0.8)   \n            axis[0].set_xlabel(\"bp\")\n            axis[0].set_ylabel(\"Read counts\")\n            axis[1].plot(pred[tf_index, 0, :], label=\"pred\", color=\"blue\", linewidth=0.8)\n            axis[1].plot(-pred[tf_index, 1, :], color=\"blue\", linewidth=0.8)\n            axis[1].set_xlabel(\"bp\")\n            axis[1].set_ylabel(\"Predicted probabilitiy * total counts\")\n            axis[0].legend()\n            axis[1].legend()\n            plt.show()\n    plot_df = pd.concat(df_list)\n            \n    return contr, dist_start, plot_df\n```\n:::\n\n\n### Klf4 E2 enhancer (Supplementary Fig.2)\n\n::: {#c207b3de .cell execution_count=10}\n``` {.python .cell-code}\ncontr, dist_start, pred = get_contr_region(\"chr4\", start=55475545, end=55475604, dataset=tune_dataset, output_dir=FIG_DIR, dl=dl, tf_list=conf_dict[\"tf_list\"], device=device,   model=model)\n#pred.to_csv(\"/home/kathi/AML_Project/data/test_fig.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-2.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-3.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-4.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-6.png){width=1598 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-7.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-8.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-10.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-11.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-12.png){width=972 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-14.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-15.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-11-output-16.png){width=968 height=356}\n:::\n:::\n\n\n### Nanog enhancer (Supplementary Fig.2)\n\n::: {#f5b85284 .cell execution_count=11}\n``` {.python .cell-code}\ncontr, dist_start, pred = get_contr_region(\"chr6\", start=122707394, end=122707454, dataset=train_dataset, output_dir=FIG_DIR, dl=dl, tf_list=conf_dict[\"tf_list\"], device=device, model=model)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-2.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-3.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-4.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-6.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-7.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-8.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-10.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-11.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-12.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-14.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-15.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-12-output-16.png){width=959 height=356}\n:::\n:::\n\n\n### Fbx15 enhancer (Supplementary Fig.2)\n\n::: {#0faaed90 .cell execution_count=12}\n``` {.python .cell-code}\ncontr, dist_start, pred = get_contr_region(\"chr18\", start=84934461, end=84934521, dataset=train_dataset, output_dir=FIG_DIR, dl=dl, tf_list=conf_dict[\"tf_list\"], device=device, model=model)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-2.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-3.png){width=819 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-4.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-6.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-7.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-8.png){width=968 height=356}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-10.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-11.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-12.png){width=959 height=357}\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n  warnings.warn(\n/Users/pschafer/miniforge3/envs/py-env-bpnet/lib/python3.12/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n               activations. The hooks and attributes will be removed\n            after the attribution is finished\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-14.png){width=1590 height=243}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-15.png){width=830 height=206}\n:::\n\n::: {.cell-output .cell-output-display}\n![](06_interpretability_files/figure-html/cell-13-output-16.png){width=959 height=356}\n:::\n:::\n\n\n# Input x Gradient\n\nFor the same exemplary regions from the paper.\n\n```#{python}\ngrad, grad_in = input_gradient(\"chr4\", start=55475545, end=55475604, dataset=tune_dataset,output_dir=FIG_DIR, \nmodel=model, tf_list=conf_dict[\"tf_list\"], device=device)\n```\n\n### Klf4 E2 enhancer (Supplementary Fig.2)\n\n```#{python}\ngrad, grad_in = input_gradient(\"chr4\", start=55475545, end=55475604, dataset=tune_dataset,output_dir=FIG_DIR, \n model=model, tf_list=conf_dict[\"tf_list\"], device=device)\n```\n\n### Nanog enhancer (Supplementary Fig.2)\n\n```#{python}\ngrad, grad_in = input_gradient(\"chr6\", start=122707394, end=122707454, dataset=train_dataset, output_dir=FIG_DIR, \nmodel=model, tf_list=conf_dict[\"tf_list\"], device=device)\n```\n\n### Fbx15 enhancer (Supplementary Fig.2)\n\n```#{python}\ngrad, grad_in = input_gradient(\"chr17\", start=35504453, end=35504603, dataset=train_dataset, output_dir=FIG_DIR, \nmodel=model, tf_list=conf_dict[\"tf_list\"], device=device)\n```\n\n",
    "supporting": [
      "06_interpretability_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}