{
  "hash": "1f7689289b1b02bf365d9d6488a69247",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"02 Dataset and NN Architecture API\"\njupyter: py-env-bpnet\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Description\n\n- Here we document our dataset API as well as our neural network architecture API\n\n# Libraries\n\n::: {#07cb9350 .cell execution_count=1}\n``` {.python .cell-code}\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nimport seaborn as sns\nimport pandas as pd\nimport re\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom src.utils import ChIP_Nexus_Dataset\nfrom src.architectures import BPNet\n```\n:::\n\n\n# Dataset API\n\n::: {#6c9dc655 .cell execution_count=2}\n``` {.python .cell-code}\nDATA_DIR = Path(\"..\") / \"data\"\nPRC_DIR = Path(\"..\") / \"prc\"\n```\n:::\n\n\n## Example 1: Create Train Dataset for all TFs\n\nOne has to provide the set which must be one of \"train\", \"tune\", \"test\" as well as the input directory and the list of TFs one wants to model.\n\n::: {#75d4776a .cell execution_count=3}\n``` {.python .cell-code}\nwhole_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=PRC_DIR, \n                                   TF_list=['Sox2', 'Oct4', 'Klf4', 'Nanog'])\nwhole_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2', 'Oct4', 'Klf4', 'Nanog']\nSize: 93904\n```\n:::\n:::\n\n\nCheck the shapes via the `check_shapes()` method.\n\n::: {#eac209ae .cell execution_count=4}\n``` {.python .cell-code}\nwhole_dataset.check_shapes()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nself.tf_list=['Sox2', 'Oct4', 'Klf4', 'Nanog']\nself.one_hot_seqs.shape=(93904, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(93904, 4, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(93904, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(93904, 2, 1000) [idx, strand, pwidth]\n```\n:::\n:::\n\n\n## Example 2: Create Train Dataset for Sox2 \n\nIf we only want to take one or a few TFs into consideration we can specify which ones using the `TF_list` parameter. The constructor method will take care of everything and only keep the peaks that are specific to the TFs in the `TF_list`.\n\n::: {#e62f2668 .cell execution_count=5}\n``` {.python .cell-code}\nsmall_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=PRC_DIR, \n                                   TF_list=['Sox2'])\nsmall_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 6748\n```\n:::\n:::\n\n\n::: {#7abda39c .cell execution_count=6}\n``` {.python .cell-code}\nsmall_dataset.check_shapes()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(6748, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(6748, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(6748, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(6748, 2, 1000) [idx, strand, pwidth]\n```\n:::\n:::\n\n\n## Example 3: Create Train Dataset for Sox2 and High-Confidence Peaks\n\nWe might also want to filter peaks based on the qValue.\n\n::: {#0ce8dc99 .cell execution_count=7}\n``` {.python .cell-code}\ncutoff = 4.5\nsns.histplot(np.log2(small_dataset.region_info.qValue))\nplt.xlabel(\"Log2 qValue\")\nplt.title(\"Distribution of qValues\")\nplt.axvline(cutoff, color=\"red\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_APIs_files/figure-html/cell-8-output-1.png){width=593 height=449}\n:::\n:::\n\n\nLooking at the histogram of the log2 qValue, we might decide to only keep peaks with a log2 qValue above 4.5.\n\n::: {#d168ccaa .cell execution_count=8}\n``` {.python .cell-code}\nhighconf_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                      input_dir=PRC_DIR, \n                                      TF_list=[\"Sox2\"],\n                                      qval_thr=2**cutoff)\nhighconf_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 4182\n```\n:::\n:::\n\n\n::: {#334f4bcc .cell execution_count=9}\n``` {.python .cell-code}\nhighconf_dataset.check_shapes()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(4182, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(4182, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(4182, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(4182, 2, 1000) [idx, strand, pwidth]\n```\n:::\n:::\n\n\n## Example 4: Create Train Dataset for Sox2 but keep all Regions\n\nNow we might also want to create a training set that contains all the regions but only the counts for Sox2.\n\n::: {#c6e48da6 .cell execution_count=10}\n``` {.python .cell-code}\nsox2_all_regions = ChIP_Nexus_Dataset(set_name=\"train\", \n                                      input_dir=PRC_DIR, \n                                      TF_list=[\"Sox2\"], \n                                      subset=False)\nsox2_all_regions\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Sox2']\nSize: 93904\n```\n:::\n:::\n\n\n::: {#5c4bed5b .cell execution_count=11}\n``` {.python .cell-code}\nsox2_all_regions.check_shapes()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nself.tf_list=['Sox2']\nself.one_hot_seqs.shape=(93904, 4, 1000) [idx, bases, pwidth]\nself.tf_counts.shape=(93904, 1, 2, 1000) [idx, TF, strand, pwidth]\nself.ctrl_counts.shape=(93904, 2, 1000) [idx, strand, pwidth]\nself.ctrl_counts_smooth.shape=(93904, 2, 1000) [idx, strand, pwidth]\n```\n:::\n:::\n\n\n# Architecture API\n\n## Example 1: One TF, Shape Prediction, No Bias Track\n\n::: {#daa1d363 .cell execution_count=12}\n``` {.python .cell-code}\nmodel_1 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], \n                pred_total=False, bias_track=False)\nmodel_1\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n)\n```\n:::\n:::\n\n\n## Example 2: One TF, Shape & Total Counts Prediction, No Bias Track\n\n::: {#34b1c90e .cell execution_count=13}\n``` {.python .cell-code}\nmodel_2 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], pred_total=True, bias_track=False)\nmodel_2\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0): TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)\n```\n:::\n:::\n\n\n## Example 3: One TF, Shape & Total Counts Prediction, Bias\n\n::: {#8a6afa87 .cell execution_count=14}\n``` {.python .cell-code}\nmodel_3 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\"], pred_total=True, bias_track=True)\nmodel_3\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0): ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0): TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)\n```\n:::\n:::\n\n\nFeatures bias weights.\n\n::: {#c8f4a880 .cell execution_count=15}\n``` {.python .cell-code}\nmodel_3.profile_heads[0].bias_weights\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nParameter containing:\ntensor([0.0100, 0.0100], requires_grad=True)\n```\n:::\n:::\n\n\n## Example 4: All TFs, Shape & Total Counts Prediction, Bias\n\n::: {#0bdf1a86 .cell execution_count=16}\n``` {.python .cell-code}\nmodel_4 = BPNet(n_dil_layers=9, TF_list=[\"Sox2\", \"Oct4\", \"Nanog\", \"Klf4\"], pred_total=True, bias_track=True)\nmodel_4\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nBPNet(\n  (base_model): ConvLayers(\n    (conv_layers): ModuleList(\n      (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=same)\n      (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n      (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n      (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n      (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n      (9): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n    )\n  )\n  (profile_heads): ModuleList(\n    (0-3): 4 x ProfileShapeHead(\n      (deconv): ConvTranspose1d(64, 2, kernel_size=(25,), stride=(1,), padding=(12,))\n    )\n  )\n  (count_heads): ModuleList(\n    (0-3): 4 x TotalCountHead(\n      (fc1): Linear(in_features=64, out_features=32, bias=True)\n      (fc2): Linear(in_features=32, out_features=2, bias=True)\n    )\n  )\n)\n```\n:::\n:::\n\n\n# Appendix\n\n## Recreate Figure 1 e\n\n::: {#f1bcb6b5 .cell execution_count=17}\n``` {.python .cell-code}\ntest_dataset = ChIP_Nexus_Dataset(set_name=\"test\", \n                                  input_dir=PRC_DIR, \n                                  TF_list=['Oct4', 'Sox2', 'Nanog', 'Klf4'])\ntest_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\nChIP_Nexus_Dataset\nSet: test\nTFs: ['Oct4', 'Sox2', 'Nanog', 'Klf4']\nSize: 27727\n```\n:::\n:::\n\n\n::: {#687a5479 .cell execution_count=18}\n``` {.python .cell-code}\ntmp_df = test_dataset.region_info.copy().reset_index()\nidx = tmp_df.loc[(tmp_df.seqnames==\"chr1\") & (tmp_df.start > 180924752-1000) & (tmp_df.end < 180925152+1000)].index.to_numpy()[0]\n\ndiff = 180924752 - tmp_df.start[idx] + 1\nw = 400\n\nfig, axis = plt.subplots(4, 1, figsize=(6, 14))\n\nfor ax, (i, tf) in zip(axis, enumerate(test_dataset.tf_list)):\n  ax.plot(test_dataset.tf_counts[idx, i, 0, diff:(diff+w)], label=\"pos\")\n  ax.plot(-test_dataset.tf_counts[idx, i, 1, diff:(diff+w)], label=\"neg\")\n  ax.legend()\n  ax.set_title(tf)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_APIs_files/figure-html/cell-19-output-1.png){width=507 height=1096}\n:::\n:::\n\n\n## Check One-Hot Encoding\n\nTo check whether the one-hot encoding worked as expected, we compare here:\n\n1) The one-hot encoded sequence as stored in the test dataset\n\n::: {#9577aee0 .cell execution_count=19}\n``` {.python .cell-code}\nplt.imshow(test_dataset.one_hot_seqs[idx, :, diff:(diff+w)], interpolation=\"none\", aspect=\"auto\")\nplt.title(\"One-Hot Encoding from Test Dataset\")\nplt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_APIs_files/figure-html/cell-20-output-1.png){width=560 height=431}\n:::\n:::\n\n\n2) The one-hot encoded sequence obtained from reading in the mm10 genome and one-hot encoding corresponding sequence\n\n::: {#ecdc338b .cell execution_count=20}\n``` {.python .cell-code}\n#from Bio.Seq import Seq\n#from Bio import SeqIO\n#mm10_ref = SeqIO.to_dict(SeqIO.parse(DATA_DIR / \"mm10.fa\", \"fasta\"))\n#seq = mm10_ref[tmp_df.iloc[idx][\"seqnames\"]][180924752:180925152]\n#one_hot_seq = np.zeros((4, 400))\n#for i, letter in enumerate(np.array(seq.seq)):\n#  if letter==\"A\": one_hot_seq[0, i] = 1\n#  if letter==\"C\": one_hot_seq[1, i] = 1\n#  if letter==\"G\": one_hot_seq[2, i] = 1\n#  if letter==\"T\": one_hot_seq[3, i] = 1\n#plt.imshow(one_hot_seq, interpolation=\"none\", aspect=\"auto\")\n#plt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\n#plt.title(\"One-Hot Encoding based on Reference Sequence\")\n#plt.show()\n```\n:::\n\n\n::: {#42ee8784 .cell execution_count=21}\n``` {.python .cell-code}\nimport gzip\nfrom Bio.Seq import Seq\nfrom Bio import SeqIO\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata_dir = Path(\"..\") / \"data\"\nmm10_path = data_dir / \"mm10.fa.gz\"\n\n# Parse the gzipped file on-the-fly\nwith gzip.open(mm10_path, \"rt\") as handle:\n    mm10_ref = SeqIO.to_dict(SeqIO.parse(handle, \"fasta\"))\nseq = mm10_ref[tmp_df[\"seqnames\"][idx]].seq[180924752:180925152]\n\none_hot_seq = np.zeros((4, len(seq)))\nfor i, letter in enumerate(seq):\n    if letter == \"A\": one_hot_seq[0, i] = 1\n    elif letter == \"C\": one_hot_seq[1, i] = 1\n    elif letter == \"G\": one_hot_seq[2, i] = 1\n    elif letter == \"T\": one_hot_seq[3, i] = 1\n\nplt.imshow(one_hot_seq, interpolation=\"none\", aspect=\"auto\")\nplt.yticks([0, 1, 2, 3], labels=[\"A\", \"C\", \"G\", \"T\"])\nplt.title(\"One-Hot Encoding based on Reference Sequence\")\nplt.xlabel(\"Position\")\nplt.ylabel(\"Base\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_APIs_files/figure-html/cell-22-output-1.png){width=578 height=449}\n:::\n:::\n\n\nfor the peak seen in Figure 1e\n\n::: {#8d82a4dd .cell execution_count=22}\n``` {.python .cell-code}\nnp.all(test_dataset.one_hot_seqs[idx, :, diff:(diff+w)] == one_hot_seq)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\nnp.True_\n```\n:::\n:::\n\n\nAnd we see that we get exactly the same.\n\n",
    "supporting": [
      "03_APIs_files"
    ],
    "filters": [],
    "includes": {}
  }
}