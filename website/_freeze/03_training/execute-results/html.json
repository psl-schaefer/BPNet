{
  "hash": "9d898db82554fa80a2bf68df31a9917e",
  "result": {
    "markdown": "---\ntitle: 03 Training and Metrics\nexecute:\n  freeze: auto\nformat:\n  html:\n    html-math-method: mathjax\n    theme: darkly\n    toc: true\n    number-sections: true\n    code-tools:\n      source: repo\ndescription: Training BPNet to predict the ChIP-Nexus profiles and total counts for all four TFs.\n---\n\n# Train Parameters\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nTF_LIST = [\"Nanog\", \"Klf4\", \"Oct4\", \"Sox2\"]\n#TF_LIST = [\"Nanog\"]\nINPUT_DIR = \"/home/philipp/BPNet/input/\"\nBATCH_SIZE = 64\nMAX_EPOCHS = 100  \nEARLY_STOP_PATIENCE = 4\nRESTORE_BEST_WEIGHTS = True\nplot_while_train = False\n```\n:::\n\n\n# Libraries\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nplt.style.use('dark_background')\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom src.architectures import BPNet\nfrom src.utils import ChIP_Nexus_Dataset, dummy_shape_predictions, dummy_total_counts_predictions\nfrom src.loss import neg_log_multinomial\nfrom src.metrics import permute_array, bin_max_values, bin_counts_amb, binary_labels_from_counts, compute_auprc_bins\ncolor_pal = {\"Oct4\": \"#CD5C5C\", \"Sox2\": \"#849EEB\", \"Nanog\": \"#FFE03F\", \"Klf4\": \"#92C592\", \"patchcap\": \"#827F81\"}\nimport pandas as pd\nimport sklearn.metrics as skm\nimport seaborn as sns\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing cuda device\n```\n:::\n:::\n\n\n# Data\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ntrain_dataset = ChIP_Nexus_Dataset(set_name=\"train\", \n                                   input_dir=INPUT_DIR, \n                                   TF_list=TF_LIST)\ntrain_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nChIP_Nexus_Dataset\nSet: train\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 93904\n```\n:::\n:::\n\n\nDetermine $\\lambda$ hyperparameter to weight between the negative multinomial log-likelihood for the shape prediction and the mean squared error for the total count prediction.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nlambda_param = (np.median(train_dataset.tf_counts.sum(axis=-1), axis=0)).mean() / 2\nlambda_param\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n58.6875\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndummy_shape_predictions(train_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnfiform Prediction Loss:\t490.46\nMean Prediction Loss:\t\t438.73\nPerfect Prediction Loss:\t133.78\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndummy_total_counts_predictions(train_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Prediction Loss:\t\t0.71\nPerfect Prediction Loss:\t0.00\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ntune_dataset = ChIP_Nexus_Dataset(set_name=\"tune\", \n                                  input_dir=INPUT_DIR, \n                                  TF_list=TF_LIST)\ntune_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nChIP_Nexus_Dataset\nSet: tune\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 29277\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndummy_shape_predictions(tune_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnfiform Prediction Loss:\t494.43\nMean Prediction Loss:\t\t442.46\nPerfect Prediction Loss:\t135.56\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ntest_dataset = ChIP_Nexus_Dataset(set_name=\"test\", \n                                  input_dir=INPUT_DIR, \n                                  TF_list=TF_LIST)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\ntest_dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nChIP_Nexus_Dataset\nSet: test\nTFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']\nSize: 27727\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndummy_shape_predictions(test_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnfiform Prediction Loss:\t513.48\nMean Prediction Loss:\t\t460.98\nPerfect Prediction Loss:\t139.21\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndummy_total_counts_predictions(test_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Prediction Loss:\t\t0.70\nPerfect Prediction Loss:\t0.00\n```\n:::\n:::\n\n\n# Shape Prediction\n\n## Train Loop\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nmodel = BPNet(n_dil_layers=9, TF_list=TF_LIST, pred_total=False, bias_track=True).to(device)\noptimizer = optim.Adam(model.parameters(), lr=4*1e-4)\n\ntrain_loader=DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\ntune_loader=DataLoader(tune_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n\ntrain_loss, test_loss = [], []\npatience_counter = 0\n\nfor epoch in range(MAX_EPOCHS):\n\n  # test\n  test_loss_epoch = []\n  with torch.no_grad():\n      for one_hot, tf_counts, ctrl_counts, ctrl_smooth in tune_loader:\n          one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n          profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n          loss = neg_log_multinomial(k_obs=tf_counts, p_pred=profile_pred, device=device)\n          test_loss_epoch.append(loss.item())\n      test_loss.append(sum(test_loss_epoch)/len(test_loss_epoch))\n\n  # train\n  model.train()\n  train_loss_epoch = []\n  for one_hot, tf_counts, ctrl_counts, ctrl_smooth in train_loader:\n    one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n    optimizer.zero_grad()\n    profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n    loss = neg_log_multinomial(k_obs=tf_counts, p_pred=profile_pred, device=device)\n    train_loss_epoch.append(loss.item())\n    loss.backward()\n    optimizer.step()\n  train_loss.append(sum(train_loss_epoch)/len(train_loss_epoch))\n\n  if test_loss[-1] > np.array(test_loss).min():\n    patience_counter += 1\n  else:\n    patience_counter = 0\n    best_state_dict = model.state_dict()\n\n  if patience_counter == EARLY_STOP_PATIENCE:\n    break\n\nif RESTORE_BEST_WEIGHTS:\n  model.load_state_dict(best_state_dict)\n```\n:::\n\n\n## Train and Tune Loss\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndf = pd.DataFrame({\"epoch\": np.arange(1, epoch+2), \"train\": train_loss, \"test\": test_loss})\ndf.to_csv(\"/home/philipp/BPNet/out/shape_loss.csv\")\nplt.plot(np.arange(epoch+1), np.array(train_loss), label=\"train\")\nplt.plot(np.arange(epoch+1), np.array(test_loss), label=\"test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-15-output-1.png){}\n:::\n:::\n\n\n## Save Model\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ntorch.save(obj=model, f=\"/home/philipp/BPNet/trained_models/all_tfs_shape_model.pt\")\n```\n:::\n\n\n## Evaluation\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nmodel = torch.load(\"/home/philipp/BPNet/trained_models/all_tfs_shape_model.pt\")\n```\n:::\n\n\n### Check Examples\n\nPlotting the real counts and the predictions for the first batch from the tune dataset.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ntune_loader=DataLoader(tune_dataset, batch_size=10, shuffle=False, num_workers=0, pin_memory=True)\none_hot, tf_counts, ctrl_counts, ctrl_smooth = next(tune_loader.__iter__())\none_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\nprofile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth).to(\"cpu\").detach().numpy()\ntf_counts = tf_counts.to(\"cpu\").detach().numpy()\nscaled_pred = profile_pred * tf_counts.sum(axis=-1)[:,:,:,None]\nlw = 0.8\n```\n:::\n\n\n#### Nanog\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ntf = 0\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-19-output-10.png){}\n:::\n:::\n\n\n#### Klf4\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ntf = 1\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-20-output-10.png){}\n:::\n:::\n\n\n#### Oct4\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ntf = 2\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-21-output-10.png){}\n:::\n:::\n\n\n#### Sox2\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\ntf = 3\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-22-output-10.png){}\n:::\n:::\n\n\n### Precision and Recall\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ntest_pred = torch.zeros(test_dataset.tf_counts.shape, dtype=torch.float32).to(device)\nwith torch.no_grad():\n    for batch_idx, data in enumerate(test_dataloader):\n        #print(batch_idx, batch_idx + 100)#, data)\n        one_hot, tf_counts, ctrl_counts, ctrl_smooth = data\n        one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n        profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n        #print(profile_pred.shape)\n        start = batch_idx*BATCH_SIZE\n        end = (batch_idx+1)*BATCH_SIZE if (batch_idx+1)*BATCH_SIZE < test_dataset.tf_counts.shape[0] else test_dataset.tf_counts.shape[0]\n        test_pred[start:end, :, :, :] = profile_pred\n```\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndef plot_prc(test_dataset, test_pred, tf_index, tf_name, plot = True):\n    true_counts = test_dataset.tf_counts.copy()\n    #subset for one tf\n    tf_counts = true_counts[:, tf_index, :, :]\n    test_pred = test_pred.cpu().numpy().copy()\n    assert np.allclose(test_pred.sum(axis=-1), 1)\n    # subset for one tf\n    tf_pred = test_pred[:, tf_index, :, :]\n    binary_labels, pred_subset, random = binary_labels_from_counts(tf_counts, tf_pred, verbose=False)\n    precision, recall, thresholds = skm.precision_recall_curve(binary_labels, pred_subset)\n    if plot:\n        plt.plot(precision, recall,  label=f\"{tf}\")\n        plt.title(f\"Precision-Recall Curve: {tf_name}\")\n        plt.xlabel(\"recall\")\n        plt.ylabel(\"precision\")\n    else:\n        return precision, recall, thresholds\n```\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nfor i, tf in enumerate(TF_LIST):\n    plot_prc(test_dataset, test_pred, i, tf, plot=True)\n    plt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-25-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\ndf = pd.DataFrame(columns=[\"TF\", \"precision\", \"recall\"])\nfor i, tf in enumerate(TF_LIST):\n    precision, recall, thresholds = plot_prc(test_dataset, test_pred, i, tf, plot=False)\n    tmp_df = pd.DataFrame({\n      \"TF\": tf,\n      \"precision\": precision,\n      \"recall\": recall,\n    })\n    df = df.append(tmp_df)\ndf.to_csv(\"/home/philipp/BPNet/out/pr_curve_all_tfs_shape_model.csv\", index=False)\ndel df, tmp_df\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/1134583418.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/1134583418.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/1134583418.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/1134583418.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n# loop over all four TFs:\ntrue_counts = test_dataset.tf_counts.copy()\nall_pred = test_pred.cpu().numpy().copy()\npatchcap = test_dataset.ctrl_counts.copy()\nassert np.allclose(all_pred.sum(axis=-1), 1)\n\nfor tf_index, tf in enumerate(TF_LIST):\n    patchcap_cp = patchcap.copy()\n    # subset for one tf\n    pred = all_pred[:, tf_index, :, :]\n    counts = true_counts[:, tf_index, :, :]\n    # compute auPRC fro all bins\n    all = compute_auprc_bins(counts, pred, patchcap_cp, verbose=False)\n    df = pd.DataFrame(all)\n    df.to_csv(f\"/home/philipp/BPNet/out/binsizes_auprc_{tf}_shape_model.csv\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"auprc\"], label=\"BPNet\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"random_auprc\"], label=\"random profile\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"average_auprc\"], label=\"average profile\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"patchcap_auprc\"], label=\"PATCH-CAP\")\n    plt.title(f\"{tf}\")\n    plt.legend()\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-27-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-27-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-27-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-27-output-4.png){}\n:::\n:::\n\n\n# Shape & Total Counts Prediction\n\n## Train Loop\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nmodel = BPNet(n_dil_layers=9, TF_list=TF_LIST, pred_total=True, bias_track=True).to(device)\noptimizer = optim.Adam(model.parameters(), lr=4*1e-4)\n\ntrain_loader=DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\ntune_loader=DataLoader(tune_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n\ntrain_shape_loss, train_count_loss, train_loss = [], [], []\ntest_shape_loss, test_count_loss, test_loss = [], [], []\n\npatience_counter = 0\n\nfor epoch in range(MAX_EPOCHS):\n\n  # test\n  test_shape_loss_epoch, test_count_loss_epoch, test_loss_epoch = [], [], []\n  with torch.no_grad():\n    for one_hot, tf_counts, ctrl_counts, ctrl_smooth in tune_loader:\n      one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n      shape_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n      shape_loss = neg_log_multinomial(k_obs=tf_counts, p_pred=shape_pred, device=device)\n      if count_pred.min() < 0:\n        break\n      count_loss = ((torch.log(1 + count_pred) - torch.log(1 + tf_counts.sum(axis=-1)))**2).mean()\n      loss = shape_loss + lambda_param * count_loss\n      test_shape_loss_epoch.append(shape_loss.item())\n      test_count_loss_epoch.append(count_loss.item())\n      test_loss_epoch.append(loss.item())\n    test_shape_loss.append(sum(test_shape_loss_epoch)/len(test_shape_loss_epoch))\n    test_count_loss.append(sum(test_count_loss_epoch)/len(test_count_loss_epoch))\n    test_loss.append(sum(test_loss_epoch)/len(test_loss_epoch))\n\n  # train\n  model.train()\n  train_shape_loss_epoch, train_count_loss_epoch, train_loss_epoch = [], [], []\n  for one_hot, tf_counts, ctrl_counts, ctrl_smooth in train_loader:\n    one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n    optimizer.zero_grad()\n    shape_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n    shape_loss = neg_log_multinomial(k_obs=tf_counts, p_pred=shape_pred, device=device)\n    count_loss = ((torch.log(1 + count_pred) - torch.log(1 + tf_counts.sum(axis=-1)))**2).mean()\n    loss = shape_loss + lambda_param * count_loss\n    train_shape_loss_epoch.append(shape_loss.item())\n    train_count_loss_epoch.append(count_loss.item())\n    train_loss_epoch.append(loss.item())\n    loss.backward()\n    optimizer.step()\n  train_shape_loss.append(sum(train_shape_loss_epoch)/len(train_shape_loss_epoch))\n  train_count_loss.append(sum(train_count_loss_epoch)/len(train_count_loss_epoch))\n  train_loss.append(sum(train_loss_epoch)/len(train_loss_epoch))\n\n  if test_loss[-1] > np.array(test_loss).min():\n    patience_counter += 1\n  else:\n    patience_counter = 0\n    best_state_dict = model.state_dict()\n\n  if patience_counter == EARLY_STOP_PATIENCE:\n    break\n\nif RESTORE_BEST_WEIGHTS:\n  model.load_state_dict(best_state_dict)\n```\n:::\n\n\n## Train and Tune Loss\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\ndf = pd.DataFrame({\"epoch\": np.arange(1, epoch+2), \"train_shape\": train_shape_loss, \"test_shape\": test_shape_loss, \"train_count\": train_count_loss, \"test_count\": test_count_loss, \"train\": train_loss, \"test\": test_loss})\ndf.to_csv(\"/home/philipp/BPNet/out/shape_counts_loss.csv\")\nfig, axis = plt.subplots(1, 3, figsize=(12, 3))\naxis[0].plot(np.arange(1, epoch+2), np.array(train_shape_loss), label=\"train\")\naxis[0].plot(np.arange(1, epoch+2), np.array(test_shape_loss), label=\"test\")\naxis[0].set_xlabel(\"Epoch\")\naxis[0].set_ylabel(\"Loss\")\naxis[0].set_title(\"Shape Loss\")\n\naxis[1].plot(np.arange(1, epoch+2), np.array(train_count_loss), label=\"train\")\naxis[1].plot(np.arange(1, epoch+2), np.array(test_count_loss), label=\"test\")\naxis[1].set_xlabel(\"Epoch\")\naxis[1].set_ylabel(\"Loss\")\naxis[1].set_title(\"Count Loss\")\n\naxis[2].plot(np.arange(1, epoch+2), np.array(train_loss), label=\"train\")\naxis[2].plot(np.arange(1, epoch+2), np.array(test_loss), label=\"test\")\naxis[2].set_xlabel(\"Epoch\")\naxis[2].set_ylabel(\"Loss\")\naxis[2].set_title(\"Combined Loss\")\n\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-29-output-1.png){}\n:::\n:::\n\n\n## Save Model\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\ntorch.save(obj=model, f=\"/home/philipp/BPNet/trained_models/all_tfs_model.pt\")\n```\n:::\n\n\n## Evaluation\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nmodel = torch.load(\"/home/philipp/BPNet/trained_models/all_tfs_model.pt\")\n```\n:::\n\n\n### Check Examples\n\nPlotting the real counts and the predictions for the first batch from the tune dataset.\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\ntune_loader=DataLoader(tune_dataset, batch_size=10, shuffle=False, num_workers=0, pin_memory=True)\none_hot, tf_counts, ctrl_counts, ctrl_smooth = next(tune_loader.__iter__())\none_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\nprofile_pred, _ = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\nprofile_pred = profile_pred.to(\"cpu\").detach().numpy()\ntf_counts = tf_counts.to(\"cpu\").detach().numpy()\nscaled_pred = profile_pred * tf_counts.sum(axis=-1)[:,:,:,None]\nlw = 0.8\n```\n:::\n\n\n#### Specific Sequence\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\ntmp_df = test_dataset.region_info.copy().reset_index()\nidx = tmp_df.loc[(tmp_df.seqnames==\"chr1\") & (tmp_df.start > 180924752-1000) & (tmp_df.end < 180925152+1000) & (tmp_df.TF == \"Sox2\")].index.to_numpy()[0]\nprint(tmp_df.iloc[idx])\n\nshape_pred, count_pred = model.forward(torch.from_numpy(test_dataset.one_hot_seqs[idx:idx+1, ]).to(device), torch.from_numpy(test_dataset.ctrl_counts[idx:idx+1, ]).to(device), torch.from_numpy(test_dataset.ctrl_counts_smooth[idx:idx+1, ]).to(device))\n\nshape_pred = shape_pred.cpu().detach().numpy()\n\ndf = pd.DataFrame(columns=[\"position\", \"TF\", \"strand\", \"kind\", \"value\"])\n\nfor data, kind in zip([test_dataset.tf_counts[idx], shape_pred[0]], [\"counts\", \"prediction\"]):\n  for i, tf in enumerate(TF_LIST):\n    for j, strand in enumerate([\"pos\", \"neg\"]):\n      tmp_df = pd.DataFrame({\"position\": np.arange(1000), \"TF\": tf, \"strand\": strand, \"kind\": kind, \"value\": data[i, j]})\n      df = df.append(tmp_df)\ndf.to_csv(\"/home/philipp/BPNet/out/example_shape_prediction.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nindex                                97\nseqnames                           chr1\nstart                         180924435\nend                           180925434\nwidth                              1000\nstrand                                *\nTF                                 Sox2\nset                                test\nname                                NaN\nscore                              1000\nsignalValue                    17.39712\npValue                        441.17929\nqValue                        436.06531\npeak                                404\nRegion         chr1:180924435-180925434\nName: 19, dtype: object\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n/tmp/ipykernel_1221851/1462060750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n:::\n\n\n#### Nanog\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\ntf = 0\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-34-output-10.png){}\n:::\n:::\n\n\n#### Klf4\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\ntf = 1\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-35-output-10.png){}\n:::\n:::\n\n\n#### Oct4\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\ntf = 2\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-36-output-10.png){}\n:::\n:::\n\n\n#### Sox2\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\ntf = 3\nfor i in range(profile_pred.shape[0]):\n  fig, axis = plt.subplots(1, 3, figsize=(16, 4))\n  axis[0].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[0].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[1].plot(tf_counts[i, tf, 0], label=\"chip counts\", color=\"green\", linewidth=lw)\n  axis[1].plot(-tf_counts[i, tf, 1], color=\"green\", linewidth=lw)\n  axis[0].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[0].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[2].plot(scaled_pred[i, tf, 0], label=\"scaled pred\", color=\"blue\", linewidth=lw)\n  axis[2].plot(-scaled_pred[i, tf, 1], color=\"blue\", linewidth=lw)\n  axis[0].legend()\n  plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-4.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-5.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-6.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-7.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-8.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-9.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-37-output-10.png){}\n:::\n:::\n\n\n### Precision and Recall\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\ntest_pred = torch.zeros(test_dataset.tf_counts.shape, dtype=torch.float32).to(device)\ntest_count_pred = torch.zeros(test_dataset.tf_counts.shape[0:3], dtype=torch.float32).to(device)\nwith torch.no_grad():\n    for batch_idx, data in enumerate(test_dataloader):\n        #print(batch_idx, batch_idx + 100)#, data)\n        one_hot, tf_counts, ctrl_counts, ctrl_smooth = data\n        one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)\n        profile_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)\n        #print(profile_pred.shape)\n        start = batch_idx*BATCH_SIZE\n        end = (batch_idx+1)*BATCH_SIZE if (batch_idx+1)*BATCH_SIZE < test_dataset.tf_counts.shape[0] else test_dataset.tf_counts.shape[0]\n        test_pred[start:end] = profile_pred\n        test_count_pred[start:end] = count_pred\n```\n:::\n\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\ndef plot_prc(test_dataset, test_pred, tf_index, tf_name, plot = True):\n    true_counts = test_dataset.tf_counts.copy()\n    #subset for one tf\n    tf_counts = true_counts[:, tf_index, :, :]\n    test_pred = test_pred.cpu().numpy().copy()\n    assert np.allclose(test_pred.sum(axis=-1), 1)\n    # subset for one tf\n    tf_pred = test_pred[:, tf_index, :, :]\n    binary_labels, pred_subset, random = binary_labels_from_counts(tf_counts, tf_pred, verbose=False)\n    precision, recall, thresholds = skm.precision_recall_curve(binary_labels, pred_subset)\n    if plot:\n        plt.plot(recall, precision,  label=f\"{tf}\")\n        plt.title(f\"Precision-Recall Curve: {tf_name}\")\n        plt.xlabel(\"recall\")\n        plt.ylabel(\"precision\")\n    else:\n        return precision, recall, thresholds\n```\n:::\n\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nfor i, tf in enumerate(TF_LIST):\n    plot_prc(test_dataset, test_pred, i, tf, plot=True)\n    plt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-40-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\ndf = pd.DataFrame(columns=[\"TF\", \"precision\", \"recall\"])\nfor i, tf in enumerate(TF_LIST):\n    precision, recall, thresholds = plot_prc(test_dataset, test_pred, i, tf, plot=False)\n    tmp_df = pd.DataFrame({\n      \"TF\": tf,\n      \"precision\": precision,\n      \"recall\": recall,\n    })\n    df = df.append(tmp_df)\ndf.to_csv(\"/home/philipp/BPNet/out/pr_curve_all_tfs_count_model.csv\", index=False)\ndel df, tmp_df\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/4023111080.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/4023111080.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/4023111080.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_1221851/4023111080.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append(tmp_df)\n```\n:::\n:::\n\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\n# loop over all four TFs:\ntrue_counts = test_dataset.tf_counts.copy()\nall_pred = test_pred.cpu().numpy().copy()\npatchcap = test_dataset.ctrl_counts.copy()\nassert np.allclose(all_pred.sum(axis=-1), 1)\n\nfor tf_index, tf in enumerate(TF_LIST):\n    patchcap_cp = patchcap.copy()\n    # subset for one tf\n    pred = all_pred[:, tf_index, :, :]\n    counts = true_counts[:, tf_index, :, :]\n    # compute auPRC fro all bins\n    all = compute_auprc_bins(counts, pred, patchcap_cp, verbose=False)\n    df = pd.DataFrame(all)\n    df.to_csv(f\"/home/philipp/BPNet/out/binsizes_auprc_{tf}_count_model.csv\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"auprc\"], label=\"BPNet\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"random_auprc\"], label=\"random profile\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"average_auprc\"], label=\"average profile\")\n    sns.scatterplot(x=df[\"binsize\"], y=df[\"patchcap_auprc\"], label=\"PATCH-CAP\")\n    plt.title(f\"{tf}\")\n    plt.legend()\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-42-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-42-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-42-output-3.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](03_training_files/figure-html/cell-42-output-4.png){}\n:::\n:::\n\n\n### MSE and R2\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\ntrue_total_counts = test_dataset.tf_counts.sum(axis=-1).copy()\npred_total_counts = test_count_pred.cpu().detach().numpy()\ntf_means = true_total_counts.mean(axis=0)\n\ndf = pd.DataFrame(columns=[\"TF\", \"mse\", \"tss\", \"rss\", \"r2\"])\nfor i, tf in enumerate(TF_LIST):\n  mse = ((np.log1p(true_total_counts[:, i]) - np.log1p(pred_total_counts[:, i]))**2).mean()\n  tss = ((true_total_counts[:, i] - tf_means[None, i])**2).sum()\n  rss = ((true_total_counts[:, i] - pred_total_counts[:, i])**2).sum()\n  r2 = 1 - rss/tss\n  tmp_df = pd.DataFrame({\"TF\": tf, \"mse\": mse, \"tss\": tss, \"rss\": rss, \"r2\": r2}, index=[0])\n  df = pd.concat([df, tmp_df], ignore_index=True, axis=0)\ndf.to_csv(\"/home/philipp/BPNet/out/count_stats.csv\", index=False)\n```\n:::\n\n\n",
    "supporting": [
      "03_training_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}