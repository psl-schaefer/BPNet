---
title: "Training and Metrics"
jupyter: py-env-bpnet
execute:
  freeze: auto
---

# Description

- Here we train two neural networks 

- a) Predict only the shape of the TF ChIP-Nexus profiles

- b) Predict both shape and total count of the TF ChIP-Nexus profiles

# Libraries

```{python}
from pathlib import Path 

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import sklearn.metrics as skm
import seaborn as sns

from src.config import conf_dict
from src.architectures import BPNet
from src.utils import ChIP_Nexus_Dataset, dummy_shape_predictions, dummy_total_counts_predictions
from src.loss import neg_log_multinomial
from src.metrics import permute_array, bin_max_values, bin_counts_amb, binary_labels_from_counts, compute_auprc_bins

plt.style.use('dark_background')
color_pal = {"Oct4": "#CD5C5C", "Sox2": "#849EEB", "Nanog": "#FFE03F", "Klf4": "#92C592", "patchcap": "#827F81"}
```

```{python}
if torch.cuda.is_available():
  device = "cuda"
elif torch.backends.mps.is_available():
  device = torch.device("mps")
else:
  decive = "cpu"
print(f"Using {device} device")
```

# Setup

```{python}
#conf_dict["tf_list"] = ["Nanog"]
#conf_dict["batch_size"] = 248
#conf_dict["max_epochs"] = 25
#conf_dict["early_stop_patience"] = 4
#conf_dict["restore_best_weights"] = True

PRC_DIR = Path("..") / "prc"
STATS_DIR = Path("..") / "stats"
STATS_DIR.mkdir(exist_ok=True, parents=True)
MODELS_DIR = Path("..") / "trained_models"
MODELS_DIR.mkdir(exist_ok=True, parents=True)
```

# Data

```{python}
train_dataset = ChIP_Nexus_Dataset(set_name="train", 
                                   input_dir=PRC_DIR, 
                                   TF_list=conf_dict["tf_list"])
train_dataset
```

Determine $\lambda$ hyperparameter to weight between the negative multinomial log-likelihood for the shape prediction and the mean squared error for the total count prediction.

```{python}
lambda_param = (np.median(train_dataset.tf_counts.sum(axis=-1), axis=0)).mean() / 2
lambda_param
```

```{python}
dummy_shape_predictions(train_dataset)
```

```{python}
dummy_total_counts_predictions(train_dataset)
```

```{python}
tune_dataset = ChIP_Nexus_Dataset(set_name="tune", 
                                  input_dir=PRC_DIR, 
                                  TF_list=conf_dict["tf_list"])
tune_dataset
```

```{python}
dummy_shape_predictions(tune_dataset)
```

```{python}
test_dataset = ChIP_Nexus_Dataset(set_name="test", 
                                  input_dir=PRC_DIR, 
                                  TF_list=conf_dict["tf_list"])
test_dataloader = DataLoader(test_dataset, batch_size=conf_dict["batch_size"], shuffle=False, num_workers=0, pin_memory=True)
test_dataset
```

```{python}
dummy_shape_predictions(test_dataset)
```

```{python}
dummy_total_counts_predictions(test_dataset)
```

# Shape Prediction

## Train Loop

```{python}
model = BPNet(n_dil_layers=9, TF_list=conf_dict["tf_list"], pred_total=False, bias_track=True).to(device)
optimizer = optim.Adam(model.parameters(), lr=4*1e-4)

train_loader=DataLoader(train_dataset, batch_size=conf_dict["batch_size"], shuffle=True, 
                        num_workers=0, pin_memory=True)
tune_loader=DataLoader(tune_dataset, batch_size=conf_dict["batch_size"], shuffle=False, 
                       num_workers=0, pin_memory=True)

train_loss, test_loss = [], []
patience_counter = 0

for epoch in range(conf_dict["max_epochs"]):
  print(epoch)

  # test
  test_loss_epoch = []
  with torch.no_grad():
      for one_hot, tf_counts, ctrl_counts, ctrl_smooth in tune_loader:
          one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
          profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
          loss = neg_log_multinomial(k_obs=tf_counts, p_pred=profile_pred, device=device)
          test_loss_epoch.append(loss.item())
      test_loss.append(sum(test_loss_epoch)/len(test_loss_epoch))

  # train
  model.train()
  train_loss_epoch = []
  for one_hot, tf_counts, ctrl_counts, ctrl_smooth in train_loader:
    one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
    optimizer.zero_grad()
    profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
    loss = neg_log_multinomial(k_obs=tf_counts, p_pred=profile_pred, device=device)
    train_loss_epoch.append(loss.item())
    loss.backward()
    optimizer.step()
  train_loss.append(sum(train_loss_epoch)/len(train_loss_epoch))

  if test_loss[-1] > np.array(test_loss).min():
    patience_counter += 1
  else:
    patience_counter = 0
    best_state_dict = model.state_dict()

  if patience_counter == conf_dict["early_stop_patience"]:
    break

if conf_dict["restore_best_weights"]:
  model.load_state_dict(best_state_dict)
```

## Train and Tune Loss

```{python}
df = pd.DataFrame({"epoch": np.arange(1, epoch+2), "train": train_loss, "test": test_loss})
df.to_csv(STATS_DIR / "shape_loss.csv")
plt.plot(np.arange(epoch+1), np.array(train_loss), label="train")
plt.plot(np.arange(epoch+1), np.array(test_loss), label="test")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()
```

## Save Model

```{python}
torch.save(obj=model, f=MODELS_DIR / "all_tfs_shape_model.pt")
```

## Evaluation

```{python}
model = torch.load(MODELS_DIR / "all_tfs_shape_model.pt")
```

### Check Examples

Plotting the real counts and the predictions for the first batch from the tune dataset.

```{python}
tune_loader=DataLoader(tune_dataset, batch_size=10, shuffle=False, num_workers=0, pin_memory=True)
one_hot, tf_counts, ctrl_counts, ctrl_smooth = next(tune_loader.__iter__())
one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth).to("cpu").detach().numpy()
tf_counts = tf_counts.to("cpu").detach().numpy()
scaled_pred = profile_pred * tf_counts.sum(axis=-1)[:,:,:,None]
lw = 0.8
```

#### Nanog

```{python}
tf = 0
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Klf4

```{python}
tf = 1
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Oct4

```{python}
tf = 2
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Sox2

```{python}
tf = 3
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

### Precision and Recall

```{python}
test_pred = torch.zeros(test_dataset.tf_counts.shape, dtype=torch.float32).to(device)
with torch.no_grad():
    for batch_idx, data in enumerate(test_dataloader):
        #print(batch_idx, batch_idx + 100)#, data)
        one_hot, tf_counts, ctrl_counts, ctrl_smooth = data
        one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
        profile_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
        #print(profile_pred.shape)
        start = batch_idx*conf_dict["batch_size"]
        end = (batch_idx+1)*conf_dict["batch_size"] if (batch_idx+1)*conf_dict["batch_size"] < test_dataset.tf_counts.shape[0] else test_dataset.tf_counts.shape[0]
        test_pred[start:end, :, :, :] = profile_pred
```

```{python}
def plot_prc(test_dataset, test_pred, tf_index, tf_name, plot = True):
    true_counts = test_dataset.tf_counts.copy()
    #subset for one tf
    tf_counts = true_counts[:, tf_index, :, :]
    test_pred = test_pred.cpu().numpy().copy()
    assert np.allclose(test_pred.sum(axis=-1), 1)
    # subset for one tf
    tf_pred = test_pred[:, tf_index, :, :]
    binary_labels, pred_subset, random = binary_labels_from_counts(tf_counts, tf_pred, verbose=False)
    precision, recall, thresholds = skm.precision_recall_curve(binary_labels, pred_subset)
    if plot:
        plt.plot(precision, recall,  label=f"{tf}")
        plt.title(f"Precision-Recall Curve")
        plt.xlabel("recall")
        plt.ylabel("precision")
        plt.legend()
    else:
        return precision, recall, thresholds
```

```{python}
for i, tf in enumerate(conf_dict["tf_list"]):
    plot_prc(test_dataset, test_pred, i, tf, plot=True)
plt.show()
```

```{python}
df_list = []
for i, tf in enumerate(conf_dict["tf_list"]):
    precision, recall, thresholds = plot_prc(test_dataset, test_pred, i, tf, plot=False)
    tmp_df = pd.DataFrame({
      "TF": tf,
      "precision": precision,
      "recall": recall,
    })
    df_list.append(tmp_df)
df = pd.concat(df_list)
df.to_csv(STATS_DIR / "pr_curve_all_tfs_shape_model.csv", index=False)
del df, tmp_df
```

```{python}
# loop over all four TFs:
true_counts = test_dataset.tf_counts.copy()
all_pred = test_pred.cpu().numpy().copy()
patchcap = test_dataset.ctrl_counts.copy()
assert np.allclose(all_pred.sum(axis=-1), 1)

for tf_index, tf in enumerate(conf_dict["tf_list"]):
    patchcap_cp = patchcap.copy()
    # subset for one tf
    pred = all_pred[:, tf_index, :, :]
    counts = true_counts[:, tf_index, :, :]
    # compute auPRC fro all bins
    all = compute_auprc_bins(counts, pred, patchcap_cp, verbose=False)
    df = pd.DataFrame(all)
    df.to_csv(STATS_DIR / f"binsizes_auprc_{tf}_shape_model.csv")
    sns.scatterplot(x=df["binsize"], y=df["auprc"], label="BPNet")
    sns.scatterplot(x=df["binsize"], y=df["random_auprc"], label="random profile")
    sns.scatterplot(x=df["binsize"], y=df["average_auprc"], label="average profile")
    sns.scatterplot(x=df["binsize"], y=df["patchcap_auprc"], label="PATCH-CAP")
    plt.title(f"{tf}")
    plt.legend()
    plt.show()
```

# Shape & Total Counts Prediction

## Train Loop

```{python}
model = BPNet(n_dil_layers=9, TF_list=conf_dict["tf_list"], pred_total=True, bias_track=True).to(device)
optimizer = optim.Adam(model.parameters(), lr=4*1e-4)

train_loader=DataLoader(train_dataset, batch_size=conf_dict["batch_size"], shuffle=True, num_workers=0, pin_memory=True)
tune_loader=DataLoader(tune_dataset, batch_size=conf_dict["batch_size"], shuffle=False, num_workers=0, pin_memory=True)

train_shape_loss, train_count_loss, train_loss = [], [], []
test_shape_loss, test_count_loss, test_loss = [], [], []

patience_counter = 0

for epoch in range(conf_dict["max_epochs"]):

  # test
  test_shape_loss_epoch, test_count_loss_epoch, test_loss_epoch = [], [], []
  with torch.no_grad():
    for one_hot, tf_counts, ctrl_counts, ctrl_smooth in tune_loader:
      one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
      shape_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
      shape_loss = neg_log_multinomial(k_obs=tf_counts, p_pred=shape_pred, device=device)
      if count_pred.min() < 0:
        break
      count_loss = ((torch.log(1 + count_pred) - torch.log(1 + tf_counts.sum(axis=-1)))**2).mean()
      loss = shape_loss + lambda_param * count_loss
      test_shape_loss_epoch.append(shape_loss.item())
      test_count_loss_epoch.append(count_loss.item())
      test_loss_epoch.append(loss.item())
    test_shape_loss.append(sum(test_shape_loss_epoch)/len(test_shape_loss_epoch))
    test_count_loss.append(sum(test_count_loss_epoch)/len(test_count_loss_epoch))
    test_loss.append(sum(test_loss_epoch)/len(test_loss_epoch))

  # train
  model.train()
  train_shape_loss_epoch, train_count_loss_epoch, train_loss_epoch = [], [], []
  for one_hot, tf_counts, ctrl_counts, ctrl_smooth in train_loader:
    one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
    optimizer.zero_grad()
    shape_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
    shape_loss = neg_log_multinomial(k_obs=tf_counts, p_pred=shape_pred, device=device)
    count_loss = ((torch.log(1 + count_pred) - torch.log(1 + tf_counts.sum(axis=-1)))**2).mean()
    loss = shape_loss + lambda_param * count_loss
    train_shape_loss_epoch.append(shape_loss.item())
    train_count_loss_epoch.append(count_loss.item())
    train_loss_epoch.append(loss.item())
    loss.backward()
    optimizer.step()
  train_shape_loss.append(sum(train_shape_loss_epoch)/len(train_shape_loss_epoch))
  train_count_loss.append(sum(train_count_loss_epoch)/len(train_count_loss_epoch))
  train_loss.append(sum(train_loss_epoch)/len(train_loss_epoch))

  if test_loss[-1] > np.array(test_loss).min():
    patience_counter += 1
  else:
    patience_counter = 0
    best_state_dict = model.state_dict()

  if patience_counter == conf_dict["early_stop_patience"]:
    break

if conf_dict["restore_best_weights"]:
  model.load_state_dict(best_state_dict)
```

## Train and Tune Loss

```{python}
df = pd.DataFrame({"epoch": np.arange(1, epoch+2), "train_shape": train_shape_loss, "test_shape": test_shape_loss, "train_count": train_count_loss, "test_count": test_count_loss, "train": train_loss, "test": test_loss})
df.to_csv(STATS_DIR / "shape_counts_loss.csv")
fig, axis = plt.subplots(1, 3, figsize=(12, 3))
axis[0].plot(np.arange(1, epoch+2), np.array(train_shape_loss), label="train")
axis[0].plot(np.arange(1, epoch+2), np.array(test_shape_loss), label="test")
axis[0].set_xlabel("Epoch")
axis[0].set_ylabel("Loss")
axis[0].set_title("Shape Loss")

axis[1].plot(np.arange(1, epoch+2), np.array(train_count_loss), label="train")
axis[1].plot(np.arange(1, epoch+2), np.array(test_count_loss), label="test")
axis[1].set_xlabel("Epoch")
axis[1].set_ylabel("Loss")
axis[1].set_title("Count Loss")

axis[2].plot(np.arange(1, epoch+2), np.array(train_loss), label="train")
axis[2].plot(np.arange(1, epoch+2), np.array(test_loss), label="test")
axis[2].set_xlabel("Epoch")
axis[2].set_ylabel("Loss")
axis[2].set_title("Combined Loss")

plt.legend()
plt.show()
```

## Save Model

```{python}
torch.save(obj=model, f=MODELS_DIR / "all_tfs_model.pt")
```

## Evaluation

```{python}
model = torch.load(MODELS_DIR / "all_tfs_model.pt")
```

### Check Examples

Plotting the real counts and the predictions for the first batch from the tune dataset.

```{python}
tune_loader=DataLoader(tune_dataset, batch_size=10, shuffle=False, num_workers=0, pin_memory=True)
one_hot, tf_counts, ctrl_counts, ctrl_smooth = next(tune_loader.__iter__())
one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
profile_pred, _ = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
profile_pred = profile_pred.to("cpu").detach().numpy()
tf_counts = tf_counts.to("cpu").detach().numpy()
scaled_pred = profile_pred * tf_counts.sum(axis=-1)[:,:,:,None]
lw = 0.8
```

#### Specific Sequence

```{python}
tmp_df = test_dataset.region_info.copy().reset_index()
idx = tmp_df.loc[(tmp_df.seqnames=="chr1") & (tmp_df.start > 180924752-1000) & (tmp_df.end < 180925152+1000) & (tmp_df.TF == "Sox2")].index.to_numpy()[0]
print(tmp_df.iloc[idx])

shape_pred, count_pred = model.forward(torch.from_numpy(test_dataset.one_hot_seqs[idx:idx+1, ]).to(device), torch.from_numpy(test_dataset.ctrl_counts[idx:idx+1, ]).to(device), torch.from_numpy(test_dataset.ctrl_counts_smooth[idx:idx+1, ]).to(device))

shape_pred = shape_pred.cpu().detach().numpy()

df_list = []
for data, kind in zip([test_dataset.tf_counts[idx], shape_pred[0]], ["counts", "prediction"]):
  for i, tf in enumerate(conf_dict["tf_list"]):
    for j, strand in enumerate(["pos", "neg"]):
      tmp_df = pd.DataFrame({"position": np.arange(1000), "TF": tf, "strand": strand, "kind": kind, "value": data[i, j]})
      df_list.append(tmp_df)
df = pd.concat(df_list)
df.to_csv(STATS_DIR / "example_shape_prediction.csv")
```

#### Nanog

```{python}
tf = 0
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Klf4

```{python}
tf = 1
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Oct4

```{python}
tf = 2
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

#### Sox2

```{python}
tf = 3
for i in range(profile_pred.shape[0]):
  fig, axis = plt.subplots(1, 3, figsize=(16, 4))
  axis[0].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[0].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[1].plot(tf_counts[i, tf, 0], label="chip counts", color="green", linewidth=lw)
  axis[1].plot(-tf_counts[i, tf, 1], color="green", linewidth=lw)
  axis[0].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[0].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[2].plot(scaled_pred[i, tf, 0], label="scaled pred", color="blue", linewidth=lw)
  axis[2].plot(-scaled_pred[i, tf, 1], color="blue", linewidth=lw)
  axis[0].legend()
  plt.show()
```

### Precision and Recall

```{python}
test_pred = torch.zeros(test_dataset.tf_counts.shape, dtype=torch.float32).to(device)
test_count_pred = torch.zeros(test_dataset.tf_counts.shape[0:3], dtype=torch.float32).to(device)
with torch.no_grad():
    for batch_idx, data in enumerate(test_dataloader):
        #print(batch_idx, batch_idx + 100)#, data)
        one_hot, tf_counts, ctrl_counts, ctrl_smooth = data
        one_hot, tf_counts, ctrl_counts, ctrl_smooth = one_hot.to(device), tf_counts.to(device), ctrl_counts.to(device), ctrl_smooth.to(device)
        profile_pred, count_pred = model.forward(sequence=one_hot, bias_raw=ctrl_counts, bias_smooth=ctrl_smooth)
        #print(profile_pred.shape)
        start = batch_idx*conf_dict["batch_size"]
        end = (batch_idx+1)*conf_dict["batch_size"] if (batch_idx+1)*conf_dict["batch_size"] < test_dataset.tf_counts.shape[0] else test_dataset.tf_counts.shape[0]
        test_pred[start:end] = profile_pred
        test_count_pred[start:end] = count_pred
```

```{python}
def plot_prc(test_dataset, test_pred, tf_index, tf_name, plot = True):
    true_counts = test_dataset.tf_counts.copy()
    #subset for one tf
    tf_counts = true_counts[:, tf_index, :, :]
    test_pred = test_pred.cpu().numpy().copy()
    assert np.allclose(test_pred.sum(axis=-1), 1)
    # subset for one tf
    tf_pred = test_pred[:, tf_index, :, :]
    binary_labels, pred_subset, random = binary_labels_from_counts(tf_counts, tf_pred, verbose=False)
    precision, recall, thresholds = skm.precision_recall_curve(binary_labels, pred_subset)
    if plot:
        plt.plot(recall, precision,  label=f"{tf}")
        plt.title(f"Precision-Recall Curve: {tf_name}")
        plt.xlabel("recall")
        plt.ylabel("precision")
    else:
        return precision, recall, thresholds
```

```{python}
for i, tf in enumerate(conf_dict["tf_list"]):
    plot_prc(test_dataset, test_pred, i, tf, plot=True)
    plt.legend()
```

```{python}
df_list = []
for i, tf in enumerate(conf_dict["tf_list"]):
    precision, recall, thresholds = plot_prc(test_dataset, test_pred, i, tf, plot=False)
    tmp_df = pd.DataFrame({
      "TF": tf,
      "precision": precision,
      "recall": recall,
    })
    df_list.append(tmp_df)
df = pd.concat(df_list)
df.to_csv(STATS_DIR / "pr_curve_all_tfs_count_model.csv", index=False)
del df, tmp_df
```

```{python}
# loop over all four TFs:
true_counts = test_dataset.tf_counts.copy()
all_pred = test_pred.cpu().numpy().copy()
patchcap = test_dataset.ctrl_counts.copy()
assert np.allclose(all_pred.sum(axis=-1), 1)

for tf_index, tf in enumerate(conf_dict["tf_list"]):
    patchcap_cp = patchcap.copy()
    # subset for one tf
    pred = all_pred[:, tf_index, :, :]
    counts = true_counts[:, tf_index, :, :]
    # compute auPRC fro all bins
    all = compute_auprc_bins(counts, pred, patchcap_cp, verbose=False)
    df = pd.DataFrame(all)
    df.to_csv(STATS_DIR / f"binsizes_auprc_{tf}_count_model.csv")
    sns.scatterplot(x=df["binsize"], y=df["auprc"], label="BPNet")
    sns.scatterplot(x=df["binsize"], y=df["random_auprc"], label="random profile")
    sns.scatterplot(x=df["binsize"], y=df["average_auprc"], label="average profile")
    sns.scatterplot(x=df["binsize"], y=df["patchcap_auprc"], label="PATCH-CAP")
    plt.title(f"{tf}")
    plt.legend()
    plt.show()
```

### MSE and R2

```{python}
true_total_counts = test_dataset.tf_counts.sum(axis=-1).copy()
pred_total_counts = test_count_pred.cpu().detach().numpy()
tf_means = true_total_counts.mean(axis=0)

df = pd.DataFrame(columns=["TF", "mse", "tss", "rss", "r2"])
for i, tf in enumerate(conf_dict["tf_list"]):
  mse = ((np.log1p(true_total_counts[:, i]) - np.log1p(pred_total_counts[:, i]))**2).mean()
  tss = ((true_total_counts[:, i] - tf_means[None, i])**2).sum()
  rss = ((true_total_counts[:, i] - pred_total_counts[:, i])**2).sum()
  r2 = 1 - rss/tss
  tmp_df = pd.DataFrame({"TF": tf, "mse": mse, "tss": tss, "rss": rss, "r2": r2}, index=[0])
  df = pd.concat([df, tmp_df], ignore_index=True, axis=0)
df.to_csv(STATS_DIR / "count_stats.csv", index=False)
```